#!/usr/bin/env python3
"""
æ£€æŸ¥CREATINGçŠ¶æ€çš„ç´¢å¼•è¯¦æƒ…
"""

import sys
import os
from datetime import datetime, timezone

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from sqlalchemy import select
    from aperag.db.models import Document, DocumentIndex, DocumentIndexStatus
    from aperag.config import get_sync_session
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)


def check_creating_indexes():
    """æ£€æŸ¥CREATINGçŠ¶æ€çš„ç´¢å¼•"""
    print("=" * 80)
    print("æ£€æŸ¥CREATINGçŠ¶æ€çš„ç´¢å¼•")
    print("=" * 80)

    for session in get_sync_session():
        # æŸ¥è¯¢æ‰€æœ‰CREATINGçŠ¶æ€çš„ç´¢å¼•
        index_stmt = select(DocumentIndex).where(
            DocumentIndex.status == DocumentIndexStatus.CREATING
        )
        index_result = session.execute(index_stmt)
        indexes = index_result.scalars().all()

        if not indexes:
            print("\nâœ… æ²¡æœ‰CREATINGçŠ¶æ€çš„ç´¢å¼•")
            return

        print(f"\næ‰¾åˆ° {len(indexes)} ä¸ªCREATINGçŠ¶æ€çš„ç´¢å¼•:\n")

        now = datetime.now(timezone.utc)
        for idx in indexes:
            # è·å–æ–‡æ¡£ä¿¡æ¯
            doc_stmt = select(Document).where(Document.id == idx.document_id)
            doc_result = session.execute(doc_stmt)
            doc = doc_result.scalar_one_or_none()

            # è®¡ç®—ç­‰å¾…æ—¶é—´
            if idx.gmt_updated:
                elapsed = now - (idx.gmt_updated.replace(tzinfo=timezone.utc)
                                 if idx.gmt_updated.tzinfo is None else idx.gmt_updated)
                elapsed_minutes = elapsed.total_seconds() / 60
                elapsed_hours = elapsed_minutes / 60
            else:
                elapsed_minutes = 0
                elapsed_hours = 0

            index_type = idx.index_type.value if hasattr(
                idx.index_type, 'value') else str(idx.index_type)

            print(f"ğŸ“„ æ–‡æ¡£: {doc.name if doc else 'æœªçŸ¥'} (ID: {idx.document_id})")
            print(f"   ç´¢å¼•ç±»å‹: {index_type}")
            print(
                f"   çŠ¶æ€: {idx.status.value if hasattr(idx.status, 'value') else idx.status}")
            print(f"   ç‰ˆæœ¬: {idx.version}, å·²è§‚å¯Ÿç‰ˆæœ¬: {idx.observed_version}")
            print(f"   æ›´æ–°æ—¶é—´: {idx.gmt_updated}")
            if elapsed_hours >= 1:
                print(
                    f"   âš ï¸  å·²ç­‰å¾…: {elapsed_hours:.1f} å°æ—¶ ({elapsed_minutes:.1f} åˆ†é’Ÿ)")
            else:
                print(f"   å·²ç­‰å¾…: {elapsed_minutes:.1f} åˆ†é’Ÿ")
            if idx.error_message:
                print(f"   âŒ é”™è¯¯ä¿¡æ¯: {idx.error_message[:200]}")
            print()

        # ç»Ÿè®¡
        stuck_count = sum(1 for idx in indexes if idx.gmt_updated and
                          (now - (idx.gmt_updated.replace(tzinfo=timezone.utc)
                                  if idx.gmt_updated.tzinfo is None else idx.gmt_updated)).total_seconds() > 300)
        if stuck_count > 0:
            print(f"\nâš ï¸  æœ‰ {stuck_count} ä¸ªç´¢å¼•å¯èƒ½å¡ä½äº†ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰")
            print("\nğŸ’¡ å»ºè®®:")
            print("  1. æ£€æŸ¥Celery workeræ˜¯å¦æ­£å¸¸è¿è¡Œ:")
            print("     docker ps | grep celeryworker")
            print("  2. æŸ¥çœ‹Celery workeræ—¥å¿—:")
            print("     docker logs aperag-celeryworker --tail 100")
            print("  3. æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡åœ¨æ‰§è¡Œ:")
            print(
                "     docker exec aperag-celeryworker celery -A config.celery_app inspect active")
            print("  4. å¦‚æœç´¢å¼•ç¡®å®å¡ä½äº†ï¼Œå¯ä»¥é‡ç½®çŠ¶æ€:")
            print(
                "     docker exec aperag-celeryworker python /app/reset_stuck_indexes.py")

        break


if __name__ == "__main__":
    try:
        check_creating_indexes()
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
