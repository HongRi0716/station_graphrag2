#!/usr/bin/env python3
"""
æ£€æŸ¥æ–‡æ¡£è§£æpendingçŠ¶æ€çš„è¯Šæ–­è„šæœ¬

ç”¨äºæ£€æŸ¥ä¸ºä»€ä¹ˆæ–‡æ¡£è§£æçŠ¶æ€ä¸€ç›´å¤„äºpending
"""

import sys
import os
from datetime import datetime, timezone
from collections import defaultdict

# Add the project root to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from aperag.config import get_sync_session
    from aperag.db.models import (
        Document,
        DocumentIndex,
        DocumentIndexType,
        DocumentIndexStatus,
        DocumentStatus,
        Collection,
    )
    from aperag.tasks.reconciler import DocumentIndexReconciler
    from aperag.utils.constant import IndexAction
    from sqlalchemy import select, and_, or_, func
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç¯å¢ƒä¸­è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


def find_document_by_name(document_name: str):
    """é€šè¿‡æ–‡ä»¶åæŸ¥æ‰¾æ–‡æ¡£"""
    print("=" * 80)
    print(f"1. æŸ¥æ‰¾æ–‡æ¡£: {document_name}")
    print("=" * 80)

    for session in get_sync_session():
        # å°è¯•ç²¾ç¡®åŒ¹é…
        stmt = select(Document).where(Document.name == document_name)
        result = session.execute(stmt)
        document = result.scalar_one_or_none()

        if not document:
            # å°è¯•æ¨¡ç³ŠåŒ¹é…
            stmt = select(Document).where(
                Document.name.like(f"%{document_name}%"))
            result = session.execute(stmt)
            documents = result.scalars().all()

            if len(documents) == 1:
                document = documents[0]
            elif len(documents) > 1:
                print(f"\nâš ï¸  æ‰¾åˆ° {len(documents)} ä¸ªåŒ¹é…çš„æ–‡æ¡£:")
                for i, doc in enumerate(documents, 1):
                    print(
                        f"   {i}. {doc.name} (ID: {doc.id}, çŠ¶æ€: {doc.status})")
                print("\nè¯·ä½¿ç”¨æ–‡æ¡£IDè¿›è¡Œç²¾ç¡®æŸ¥è¯¢")
                return None

        if document:
            print(f"\nâœ… æ‰¾åˆ°æ–‡æ¡£:")
            print(f"   ID: {document.id}")
            print(f"   åç§°: {document.name}")
            print(f"   çŠ¶æ€: {document.status}")
            print(f"   å¤§å°: {document.size} bytes")
            print(f"   åˆ›å»ºæ—¶é—´: {document.gmt_created}")
            print(f"   æ›´æ–°æ—¶é—´: {document.gmt_updated}")
            return document

    print(f"\nâŒ æœªæ‰¾åˆ°æ–‡æ¡£: {document_name}")
    return None


def check_document_indexes(document_id: str):
    """æ£€æŸ¥æ–‡æ¡£çš„æ‰€æœ‰ç´¢å¼•çŠ¶æ€"""
    print("\n" + "=" * 80)
    print(f"2. æ£€æŸ¥æ–‡æ¡£ç´¢å¼•çŠ¶æ€ (Document ID: {document_id})")
    print("=" * 80)

    for session in get_sync_session():
        # æŸ¥è¯¢æ‰€æœ‰ç´¢å¼•
        stmt = select(DocumentIndex).where(
            DocumentIndex.document_id == document_id)
        result = session.execute(stmt)
        indexes = result.scalars().all()

        if not indexes:
            print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•ç´¢å¼•è®°å½•")
            print("   å¯èƒ½åŸå› :")
            print("   - æ–‡æ¡£å°šæœªåˆ›å»ºç´¢å¼•è®°å½•")
            print("   - ç´¢å¼•è®°å½•å·²è¢«åˆ é™¤")
            return None

        print(f"\nğŸ“Š æ‰¾åˆ° {len(indexes)} ä¸ªç´¢å¼•è®°å½•:")

        pending_indexes = []
        for index in indexes:
            status_icon = "â³" if index.status == DocumentIndexStatus.PENDING else \
                "ğŸ”„" if index.status == DocumentIndexStatus.CREATING else \
                "âœ…" if index.status == DocumentIndexStatus.ACTIVE else \
                "âŒ" if index.status == DocumentIndexStatus.FAILED else "â“"

            index_type_str = index.index_type.value if hasattr(
                index.index_type, 'value') else str(index.index_type)
            status_str = index.status.value if hasattr(
                index.status, 'value') else str(index.status)

            print(f"\n   {status_icon} {index_type_str}:")
            print(f"      çŠ¶æ€: {status_str}")
            print(f"      ç‰ˆæœ¬: {index.version} (å·²å¤„ç†: {index.observed_version})")
            print(f"      åˆ›å»ºæ—¶é—´: {index.gmt_created}")
            print(f"      æ›´æ–°æ—¶é—´: {index.gmt_updated}")
            if index.gmt_last_reconciled:
                print(f"      æœ€ååè°ƒæ—¶é—´: {index.gmt_last_reconciled}")
            if index.error_message:
                print(f"      âŒ é”™è¯¯ä¿¡æ¯: {index.error_message}")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åè°ƒ
            needs_reconciliation = False
            if index.status == DocumentIndexStatus.PENDING:
                if index.observed_version < index.version:
                    needs_reconciliation = True
                    if index.version == 1:
                        action = "CREATE"
                    else:
                        action = "UPDATE"
                    print(
                        f"      âš ï¸  éœ€è¦åè°ƒ: {action} (version={index.version}, observed={index.observed_version})")

            if index.status == DocumentIndexStatus.PENDING:
                pending_indexes.append(index)

        if pending_indexes:
            print(f"\nâš ï¸  å‘ç° {len(pending_indexes)} ä¸ªPENDINGçŠ¶æ€çš„ç´¢å¼•:")
            for index in pending_indexes:
                index_type_str = index.index_type.value if hasattr(
                    index.index_type, 'value') else str(index.index_type)
                print(
                    f"   - {index_type_str}: version={index.version}, observed={index.observed_version}")

        return indexes

    return None


def check_reconciler_detection(document_id: str):
    """æ£€æŸ¥reconcileræ˜¯å¦èƒ½æ£€æµ‹åˆ°è¿™ä¸ªæ–‡æ¡£éœ€è¦å¤„ç†"""
    print("\n" + "=" * 80)
    print(f"3. æ£€æŸ¥Reconcileræ£€æµ‹çŠ¶æ€ (Document ID: {document_id})")
    print("=" * 80)

    for session in get_sync_session():
        # æ¨¡æ‹Ÿreconcilerçš„æ£€æµ‹é€»è¾‘
        operations = defaultdict(
            lambda: {IndexAction.CREATE: [], IndexAction.UPDATE: [], IndexAction.DELETE: []})

        # CREATEæ¡ä»¶: status=PENDING, observed_version < version, version=1
        create_stmt = select(DocumentIndex).where(
            and_(
                DocumentIndex.document_id == document_id,
                DocumentIndex.status == DocumentIndexStatus.PENDING,
                DocumentIndex.observed_version < DocumentIndex.version,
                DocumentIndex.version == 1,
            )
        )
        create_result = session.execute(create_stmt)
        create_indexes = create_result.scalars().all()

        # UPDATEæ¡ä»¶: status=PENDING, observed_version < version, version > 1
        update_stmt = select(DocumentIndex).where(
            and_(
                DocumentIndex.document_id == document_id,
                DocumentIndex.status == DocumentIndexStatus.PENDING,
                DocumentIndex.observed_version < DocumentIndex.version,
                DocumentIndex.version > 1,
            )
        )
        update_result = session.execute(update_stmt)
        update_indexes = update_result.scalars().all()

        # DELETEæ¡ä»¶: status=DELETING
        delete_stmt = select(DocumentIndex).where(
            and_(
                DocumentIndex.document_id == document_id,
                DocumentIndex.status == DocumentIndexStatus.DELETING,
            )
        )
        delete_result = session.execute(delete_stmt)
        delete_indexes = delete_result.scalars().all()

        for index in create_indexes:
            operations[document_id][IndexAction.CREATE].append(index)
        for index in update_indexes:
            operations[document_id][IndexAction.UPDATE].append(index)
        for index in delete_indexes:
            operations[document_id][IndexAction.DELETE].append(index)

        doc_operations = operations.get(document_id, {})

        total_ops = sum(len(ops) for ops in doc_operations.values())

        if total_ops == 0:
            print("\nâŒ Reconcileræœªæ£€æµ‹åˆ°éœ€è¦å¤„ç†çš„æ“ä½œ")
            print("   å¯èƒ½åŸå› :")
            print("   - ç´¢å¼•çŠ¶æ€ä¸æ˜¯PENDING")
            print("   - versionå’Œobserved_versionå·²åŒæ­¥")
            print("   - ç´¢å¼•è®°å½•ä¸å­˜åœ¨")
        else:
            print(f"\nâœ… Reconcileræ£€æµ‹åˆ° {total_ops} ä¸ªéœ€è¦å¤„ç†çš„æ“ä½œ:")
            if doc_operations[IndexAction.CREATE]:
                print(
                    f"   - CREATE: {len(doc_operations[IndexAction.CREATE])} ä¸ª")
                for idx in doc_operations[IndexAction.CREATE]:
                    idx_type_str = idx.index_type.value if hasattr(
                        idx.index_type, 'value') else str(idx.index_type)
                    print(f"     * {idx_type_str} (version={idx.version})")
            if doc_operations[IndexAction.UPDATE]:
                print(
                    f"   - UPDATE: {len(doc_operations[IndexAction.UPDATE])} ä¸ª")
                for idx in doc_operations[IndexAction.UPDATE]:
                    idx_type_str = idx.index_type.value if hasattr(
                        idx.index_type, 'value') else str(idx.index_type)
                    print(
                        f"     * {idx_type_str} (version={idx.version}, observed={idx.observed_version})")
            if doc_operations[IndexAction.DELETE]:
                print(
                    f"   - DELETE: {len(doc_operations[IndexAction.DELETE])} ä¸ª")
                for idx in doc_operations[IndexAction.DELETE]:
                    idx_type_str = idx.index_type.value if hasattr(
                        idx.index_type, 'value') else str(idx.index_type)
                    print(f"     * {idx_type_str}")

        return doc_operations


def check_celery_status():
    """æ£€æŸ¥CeleryæœåŠ¡çŠ¶æ€ï¼ˆéœ€è¦æ‰‹åŠ¨æ‰§è¡Œï¼‰"""
    print("\n" + "=" * 80)
    print("4. æ£€æŸ¥CeleryæœåŠ¡çŠ¶æ€ï¼ˆéœ€è¦æ‰‹åŠ¨æ‰§è¡Œï¼‰")
    print("=" * 80)

    print("\nè¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥CeleryæœåŠ¡:")
    print("\n1. æ£€æŸ¥Celery Workeræ˜¯å¦è¿è¡Œ:")
    print("   docker ps | grep celeryworker")

    print("\n2. æ£€æŸ¥Celery Beatæ˜¯å¦è¿è¡Œ:")
    print("   docker ps | grep celerybeat")

    print("\n3. æ£€æŸ¥æ´»è·ƒä»»åŠ¡:")
    print("   docker exec aperag-celeryworker celery -A config.celery inspect active")

    print("\n4. æ£€æŸ¥ä¿ç•™ä»»åŠ¡:")
    print("   docker exec aperag-celeryworker celery -A config.celery inspect reserved")

    print("\n5. æŸ¥çœ‹æœ€è¿‘çš„æ—¥å¿—:")
    print("   docker logs aperag-celeryworker --tail 200 | grep -i 'reconcile\\|parse\\|index'")

    print("\n6. æ‰‹åŠ¨è§¦å‘reconciliation:")
    print("   docker exec aperag-celeryworker python -c \"")
    print("   from config.celery_tasks import reconcile_indexes_task")
    print("   reconcile_indexes_task()")
    print("   \"")


def check_collection_config(document_id: str):
    """æ£€æŸ¥Collectioné…ç½®"""
    print("\n" + "=" * 80)
    print(f"5. æ£€æŸ¥Collectioné…ç½®")
    print("=" * 80)

    for session in get_sync_session():
        # æŸ¥è¯¢æ–‡æ¡£
        doc_stmt = select(Document).where(Document.id == document_id)
        doc_result = session.execute(doc_stmt)
        document = doc_result.scalar_one_or_none()

        if not document:
            print("\nâŒ æœªæ‰¾åˆ°æ–‡æ¡£")
            return

        # æŸ¥è¯¢Collection
        collection_stmt = select(Collection).where(
            Collection.id == document.collection_id)
        collection_result = session.execute(collection_stmt)
        collection = collection_result.scalar_one_or_none()

        if not collection:
            print("\nâŒ æœªæ‰¾åˆ°Collection")
            return

        print(f"\nğŸ“š Collectionä¿¡æ¯:")
        print(f"   ID: {collection.id}")
        print(f"   åç§°: {collection.name}")
        print(f"   çŠ¶æ€: {collection.status}")

        # æ£€æŸ¥é…ç½®
        try:
            from aperag.schema.utils import parseCollectionConfig
            config = parseCollectionConfig(collection.config)

            print(f"\nğŸ“‹ ç´¢å¼•é…ç½®:")
            print(f"   Vectorç´¢å¼•: {'âœ… å¯ç”¨' if config.enable_vector else 'âŒ ç¦ç”¨'}")
            print(
                f"   Fulltextç´¢å¼•: {'âœ… å¯ç”¨' if config.enable_fulltext else 'âŒ ç¦ç”¨'}")
            print(f"   Graphç´¢å¼•: {'âœ… å¯ç”¨' if config.enable_graph else 'âŒ ç¦ç”¨'}")
            print(f"   Visionç´¢å¼•: {'âœ… å¯ç”¨' if config.enable_vision else 'âŒ ç¦ç”¨'}")
            print(
                f"   Summaryç´¢å¼•: {'âœ… å¯ç”¨' if config.enable_summary else 'âŒ ç¦ç”¨'}")
        except Exception as e:
            print(f"\nâš ï¸  è§£æé…ç½®å¤±è´¥: {e}")


def provide_solutions(document_id: str, indexes):
    """æä¾›è§£å†³æ–¹æ¡ˆ"""
    print("\n" + "=" * 80)
    print("6. è§£å†³æ–¹æ¡ˆå»ºè®®")
    print("=" * 80)

    if not indexes:
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²æ­£ç¡®ä¸Šä¼ ")
        print("   2. æ£€æŸ¥Collectioné…ç½®æ˜¯å¦æ­£ç¡®")
        print("   3. å°è¯•é‡æ–°ç¡®è®¤æ–‡æ¡£ï¼ˆå¦‚æœçŠ¶æ€æ˜¯UPLOADEDï¼‰")
        return

    pending_count = sum(1 for idx in indexes if idx.status ==
                        DocumentIndexStatus.PENDING)
    creating_count = sum(1 for idx in indexes if idx.status ==
                         DocumentIndexStatus.CREATING)
    failed_count = sum(1 for idx in indexes if idx.status ==
                       DocumentIndexStatus.FAILED)

    if pending_count > 0:
        print(f"\nâš ï¸  å‘ç° {pending_count} ä¸ªPENDINGçŠ¶æ€çš„ç´¢å¼•")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("   1. æ£€æŸ¥Celery Beatæ˜¯å¦æ­£å¸¸è¿è¡Œï¼ˆæ¯30ç§’è¿è¡Œreconcile_indexes_taskï¼‰")
        print("   2. æ£€æŸ¥Celery Workeræ˜¯å¦æ­£å¸¸è¿è¡Œ")
        print("   3. æ‰‹åŠ¨è§¦å‘reconciliation:")
        print("      docker exec aperag-celeryworker python -c \\")
        print("        'from config.celery_tasks import reconcile_indexes_task; reconcile_indexes_task()'")
        print("   4. æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„workerèµ„æºå¤„ç†ä»»åŠ¡")
        print("   5. æŸ¥çœ‹Celeryæ—¥å¿—æŸ¥æ‰¾é”™è¯¯ä¿¡æ¯")

    if creating_count > 0:
        print(f"\nğŸ”„ å‘ç° {creating_count} ä¸ªCREATINGçŠ¶æ€çš„ç´¢å¼•")
        print("   è¿™äº›ç´¢å¼•æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆ")
        print("   å¦‚æœé•¿æ—¶é—´å¤„äºCREATINGçŠ¶æ€ï¼Œå¯èƒ½æ˜¯:")
        print("   - ä»»åŠ¡æ‰§è¡Œå¤±è´¥ä½†æœªæ­£ç¡®æ›´æ–°çŠ¶æ€")
        print("   - Workerèµ„æºä¸è¶³")
        print("   - ç½‘ç»œæˆ–APIè¿æ¥é—®é¢˜")

    if failed_count > 0:
        print(f"\nâŒ å‘ç° {failed_count} ä¸ªFAILEDçŠ¶æ€çš„ç´¢å¼•")
        print("   éœ€è¦æŸ¥çœ‹é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤åé‡æ–°åˆ›å»ºç´¢å¼•")
        print("   å¯ä»¥é€šè¿‡APIæˆ–Webç•Œé¢é‡å»ºç´¢å¼•")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ£€æŸ¥æ–‡æ¡£è§£æpendingçŠ¶æ€çš„è¯Šæ–­å·¥å…·")
    parser.add_argument(
        "--document-name",
        type=str,
        help="æ–‡æ¡£åç§°ï¼ˆæ”¯æŒéƒ¨åˆ†åŒ¹é…ï¼‰"
    )
    parser.add_argument(
        "--document-id",
        type=str,
        help="æ–‡æ¡£IDï¼ˆç²¾ç¡®æŸ¥è¯¢ï¼‰"
    )

    args = parser.parse_args()

    print("=" * 80)
    print("æ–‡æ¡£è§£æPendingçŠ¶æ€è¯Šæ–­å·¥å…·")
    print("=" * 80)
    print("\nğŸ’¡ æç¤º: å¦‚æœåœ¨æœ¬åœ°è¿è¡Œå¤±è´¥ï¼Œè¯·åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œ:")
    print("   docker exec aperag-celeryworker python check_document_pending.py --document-name 'é¢å·å˜æ¥çº¿å›¾'")
    print("=" * 80)

    document = None

    # æŸ¥æ‰¾æ–‡æ¡£
    if args.document_id:
        for session in get_sync_session():
            stmt = select(Document).where(Document.id == args.document_id)
            result = session.execute(stmt)
            document = result.scalar_one_or_none()
            if document:
                print(f"\nâœ… æ‰¾åˆ°æ–‡æ¡£: {document.name} (ID: {document.id})")
                break
    elif args.document_name:
        document = find_document_by_name(args.document_name)
    else:
        print("\nâŒ è¯·æä¾› --document-name æˆ– --document-id å‚æ•°")
        parser.print_help()
        return

    if not document:
        print("\nâŒ æœªæ‰¾åˆ°æ–‡æ¡£ï¼Œæ— æ³•ç»§ç»­è¯Šæ–­")
        return

    document_id = document.id

    # æ£€æŸ¥ç´¢å¼•çŠ¶æ€
    indexes = check_document_indexes(document_id)

    # æ£€æŸ¥reconcileræ£€æµ‹
    doc_operations = check_reconciler_detection(document_id)

    # æ£€æŸ¥Collectioné…ç½®
    check_collection_config(document_id)

    # æ£€æŸ¥CeleryçŠ¶æ€
    check_celery_status()

    # æä¾›è§£å†³æ–¹æ¡ˆ
    provide_solutions(document_id, indexes)

    # æ€»ç»“
    print("\n" + "=" * 80)
    print("è¯Šæ–­æ€»ç»“")
    print("=" * 80)

    if indexes:
        status_summary = defaultdict(int)
        for idx in indexes:
            status_summary[idx.status.value] += 1

        print(f"\nç´¢å¼•çŠ¶æ€ç»Ÿè®¡:")
        for status, count in status_summary.items():
            print(f"   {status}: {count}")

    if doc_operations:
        total_ops = sum(len(ops) for ops in doc_operations.values())
        if total_ops > 0:
            print(f"\nâœ… Reconcilerå¯ä»¥æ£€æµ‹åˆ° {total_ops} ä¸ªå¾…å¤„ç†æ“ä½œ")
            print("   å¦‚æœç´¢å¼•ä»ç„¶å¤„äºPENDINGçŠ¶æ€ï¼Œå¯èƒ½åŸå› :")
            print("   - Celery Beatæœªè¿è¡Œæˆ–æœªæ­£ç¡®è°ƒåº¦reconcile_indexes_task")
            print("   - Celery Workeræœªè¿è¡Œæˆ–èµ„æºä¸è¶³")
            print("   - ä»»åŠ¡æ‰§è¡Œå¤±è´¥ä½†æœªæ­£ç¡®æ›´æ–°çŠ¶æ€")
        else:
            print("\nâš ï¸  Reconcileræœªæ£€æµ‹åˆ°éœ€è¦å¤„ç†çš„æ“ä½œ")
            print("   å¯èƒ½åŸå› :")
            print("   - ç´¢å¼•çŠ¶æ€ä¸æ˜¯PENDING")
            print("   - versionå’Œobserved_versionå·²åŒæ­¥")
    else:
        print("\nâš ï¸  Reconcileræœªæ£€æµ‹åˆ°éœ€è¦å¤„ç†çš„æ“ä½œ")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ è¯Šæ–­è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
