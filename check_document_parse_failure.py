#!/usr/bin/env python3
"""
å¿«é€Ÿè¯Šæ–­æ–‡æ¡£è§£æå¤±è´¥åŸå› 
ç”¨æ³•: python check_document_parse_failure.py "æ–‡æ¡£åç§°"
"""

import sys
import os
from datetime import datetime, timezone

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from sqlalchemy import select, and_, or_
    from aperag.db.models import Document, DocumentIndex, DocumentIndexType, DocumentIndexStatus, DocumentStatus
    from aperag.config import get_sync_session
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„Pythonç¯å¢ƒä¸­è¿è¡Œï¼Œæˆ–ä½¿ç”¨Dockerå®¹å™¨:")
    print("  docker exec aperag-celeryworker python /app/check_document_parse_failure.py \"æ–‡æ¡£åç§°\"")
    sys.exit(1)


def check_document_parse_status(document_name_pattern: str):
    """æ£€æŸ¥æ–‡æ¡£è§£æçŠ¶æ€"""
    print("=" * 80)
    print(f"æ£€æŸ¥æ–‡æ¡£è§£æçŠ¶æ€: {document_name_pattern}")
    print("=" * 80)

    for session in get_sync_session():
        # æŸ¥è¯¢æ–‡æ¡£
        doc_stmt = select(Document).where(
            Document.name.like(f"%{document_name_pattern}%")
        ).order_by(Document.gmt_created.desc())

        doc_result = session.execute(doc_stmt)
        documents = doc_result.scalars().all()

        if not documents:
            print(f"\nâŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£: {document_name_pattern}")
            print("\nğŸ’¡ å»ºè®®:")
            print("  1. æ£€æŸ¥æ–‡æ¡£åç§°æ˜¯å¦æ­£ç¡®")
            print("  2. å°è¯•ä½¿ç”¨æ–‡æ¡£åç§°çš„ä¸€éƒ¨åˆ†è¿›è¡Œæœç´¢")
            return

        print(f"\næ‰¾åˆ° {len(documents)} ä¸ªåŒ¹é…çš„æ–‡æ¡£:\n")

        for doc in documents:
            print(f"\n{'='*80}")
            print(f"ğŸ“„ æ–‡æ¡£ä¿¡æ¯:")
            print(f"   åç§°: {doc.name}")
            print(f"   ID: {doc.id}")
            print(
                f"   çŠ¶æ€: {doc.status.value if hasattr(doc.status, 'value') else doc.status}")
            print(f"   æ–‡ä»¶å¤§å°: {doc.size:,} bytes ({doc.size/1024/1024:.2f} MB)")
            print(f"   åˆ›å»ºæ—¶é—´: {doc.gmt_created}")
            print(f"   æ›´æ–°æ—¶é—´: {doc.gmt_updated}")

            # è®¡ç®—ç­‰å¾…æ—¶é—´
            if doc.gmt_updated:
                now = datetime.now(timezone.utc)
                elapsed = now - (doc.gmt_updated.replace(tzinfo=timezone.utc)
                                 if doc.gmt_updated.tzinfo is None else doc.gmt_updated)
                print(f"   å·²ç­‰å¾…: {elapsed.total_seconds()/60:.1f} åˆ†é’Ÿ")

            print(f"\nğŸ“Š ç´¢å¼•çŠ¶æ€:")

            # æŸ¥è¯¢æ‰€æœ‰ç´¢å¼•
            index_stmt = select(DocumentIndex).where(
                DocumentIndex.document_id == doc.id
            )
            index_result = session.execute(index_stmt)
            indexes = index_result.scalars().all()

            if not indexes:
                print("   âš ï¸  æœªæ‰¾åˆ°ç´¢å¼•è®°å½•ï¼ˆå¯èƒ½è¿˜æœªå¼€å§‹è§£æï¼‰")
                continue

            has_failed = False
            for idx in indexes:
                status_icon = {
                    DocumentIndexStatus.PENDING: "â³",
                    DocumentIndexStatus.CREATING: "ğŸ”„",
                    DocumentIndexStatus.ACTIVE: "âœ…",
                    DocumentIndexStatus.FAILED: "âŒ",
                    DocumentIndexStatus.DELETION_IN_PROGRESS: "ğŸ—‘ï¸",
                    DocumentIndexStatus.DELETING: "ğŸ—‘ï¸"
                }.get(idx.status, "â“")

                index_type = idx.index_type.value if hasattr(
                    idx.index_type, 'value') else str(idx.index_type)
                status = idx.status.value if hasattr(
                    idx.status, 'value') else str(idx.status)

                print(f"   {status_icon} {index_type}: {status}")

                if idx.error_message:
                    has_failed = True
                    print(f"      âŒ é”™è¯¯: {idx.error_message[:200]}...")
                    if len(idx.error_message) > 200:
                        print(f"         (é”™è¯¯ä¿¡æ¯è¿‡é•¿ï¼Œå·²æˆªæ–­)")

            # è¯Šæ–­å»ºè®®
            if has_failed:
                print(f"\nğŸ” è¯Šæ–­å»ºè®®:")

                failed_indexes = [
                    idx for idx in indexes if idx.status == DocumentIndexStatus.FAILED]
                for idx in failed_indexes:
                    error_lower = idx.error_message.lower() if idx.error_message else ""

                    if "parse" in error_lower or "docray" in error_lower or "mineru" in error_lower:
                        print(f"\n   ğŸ“‹ è§£æå¤±è´¥ ({idx.index_type.value}):")
                        print(f"      å¯èƒ½åŸå› :")
                        print(f"      1. DocRay/MinerU æœåŠ¡æœªå¯åŠ¨æˆ–ä¸å¯è®¿é—®")
                        print(f"      2. æ–‡æ¡£æ ¼å¼æŸåæˆ–ä¸æ”¯æŒ")
                        print(f"      3. æ–‡æ¡£è¿‡å¤§è¶…è¿‡é™åˆ¶")
                        print(f"      4. è§£ææœåŠ¡è¶…æ—¶")
                        print(f"\n      è§£å†³æ–¹æ¡ˆ:")
                        print(f"      1. æ£€æŸ¥è§£ææœåŠ¡çŠ¶æ€:")
                        print(f"         docker ps | grep -E 'docray|mineru'")
                        print(f"      2. æŸ¥çœ‹è§£ææœåŠ¡æ—¥å¿—:")
                        print(f"         docker logs aperag-docray --tail 50")
                        print(f"      3. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å¯ä»¥æ­£å¸¸æ‰“å¼€")
                        print(f"      4. å°è¯•é‡æ–°ä¸Šä¼ æ–‡æ¡£")

                    elif "embedding" in error_lower or "vector" in error_lower:
                        print(f"\n   ğŸ”¢ å‘é‡åŒ–å¤±è´¥ ({idx.index_type.value}):")
                        print(f"      å¯èƒ½åŸå› :")
                        print(f"      1. Embedding API å¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
                        print(f"      2. API é…é¢ä¸è¶³æˆ–è¾¾åˆ°é€Ÿç‡é™åˆ¶")
                        print(f"      3. æ–‡æœ¬è¿‡é•¿è¶…è¿‡ token é™åˆ¶")
                        print(f"      4. ç½‘ç»œæ— æ³•è®¿é—® Embedding æœåŠ¡")
                        print(f"\n      è§£å†³æ–¹æ¡ˆ:")
                        print(f"      1. æ£€æŸ¥ EMBEDDING_SERVICE_API_KEY é…ç½®")
                        print(f"      2. æ£€æŸ¥ API é…é¢å’Œé€Ÿç‡é™åˆ¶")
                        print(f"      3. æŸ¥çœ‹é”™è¯¯è¯¦æƒ…ä¸­çš„ token é™åˆ¶ä¿¡æ¯")

                    elif "graph" in error_lower or "neo4j" in error_lower or "nebula" in error_lower:
                        print(f"\n   ğŸ•¸ï¸  çŸ¥è¯†å›¾è°±å¤±è´¥ ({idx.index_type.value}):")
                        print(f"      å¯èƒ½åŸå› :")
                        print(f"      1. å›¾æ•°æ®åº“æœªè¿è¡Œæˆ–è¿æ¥å¤±è´¥")
                        print(f"      2. LLM æœåŠ¡é—®é¢˜ï¼ˆç”¨äºå®ä½“æå–ï¼‰")
                        print(f"      3. æ–‡æ¡£å†…å®¹è¿‡é•¿å¯¼è‡´å¤„ç†è¶…æ—¶")
                        print(f"\n      è§£å†³æ–¹æ¡ˆ:")
                        print(f"      1. æ£€æŸ¥å›¾æ•°æ®åº“æœåŠ¡çŠ¶æ€:")
                        print(f"         docker ps | grep -E 'neo4j|nebula'")
                        print(f"      2. æ£€æŸ¥å›¾æ•°æ®åº“è¿æ¥é…ç½®")
                        print(f"      3. æ£€æŸ¥ LLM æœåŠ¡é…ç½®")

                    elif "timeout" in error_lower:
                        print(f"\n   â±ï¸  è¶…æ—¶å¤±è´¥ ({idx.index_type.value}):")
                        print(f"      å¯èƒ½åŸå› :")
                        print(f"      1. æ–‡æ¡£è¿‡å¤§ï¼Œå¤„ç†æ—¶é—´è¿‡é•¿")
                        print(f"      2. æœåŠ¡å“åº”æ…¢")
                        print(f"      3. ç½‘ç»œè¿æ¥é—®é¢˜")
                        print(f"\n      è§£å†³æ–¹æ¡ˆ:")
                        print(f"      1. æ£€æŸ¥æ–‡æ¡£å¤§å°: {doc.size/1024/1024:.2f} MB")
                        print(f"      2. å¢åŠ è¶…æ—¶é…ç½®")
                        print(f"      3. å°è¯•é‡æ–°ä¸Šä¼ ")

                print(f"\n   ğŸ”§ ä¿®å¤æ­¥éª¤:")
                print(f"      1. æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—:")
                print(
                    f"         docker logs aperag-celeryworker --tail 200 | grep '{doc.id}'")
                print(f"      2. ä¿®å¤ä¸Šè¿°é…ç½®é—®é¢˜")
                print(f"      3. é‡å»ºå¤±è´¥çš„ç´¢å¼•:")
                print(f"         åœ¨Webç•Œé¢ä¸­ç‚¹å‡»æ–‡æ¡£çš„'é‡å»ºç´¢å¼•'æŒ‰é’®")
                print(
                    f"         æˆ–ä½¿ç”¨API: POST /api/v1/collections/{{collection_id}}/documents/{doc.id}/rebuild-indexes")

            elif doc.status == DocumentStatus.RUNNING:
                creating_indexes = [
                    idx for idx in indexes if idx.status == DocumentIndexStatus.CREATING]
                if creating_indexes:
                    print(f"\n   â³ è§£æè¿›è¡Œä¸­:")
                    print(f"      æœ‰ {len(creating_indexes)} ä¸ªç´¢å¼•æ­£åœ¨åˆ›å»ºä¸­")
                    print(f"      è¯·è€å¿ƒç­‰å¾…ï¼Œæˆ–æŸ¥çœ‹æ—¥å¿—äº†è§£è¿›åº¦")
                    print(
                        f"      docker logs aperag-celeryworker --tail 100 | grep '{doc.id}'")

            print(f"\n{'='*80}\n")

        break  # åªå¤„ç†ç¬¬ä¸€ä¸ªsession


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="è¯Šæ–­æ–‡æ¡£è§£æå¤±è´¥åŸå› ")
    parser.add_argument(
        "document_name",
        nargs="?",
        default="2-å›½å®¶ç”µç½‘å…¬å¸å˜ç”µè¿ç»´ç®¡ç†è§„",
        help="æ–‡æ¡£åç§°æˆ–åç§°çš„ä¸€éƒ¨åˆ†(æ”¯æŒæ¨¡ç³ŠåŒ¹é…)"
    )

    args = parser.parse_args()

    try:
        check_document_parse_status(args.document_name)
    except Exception as e:
        print(f"\nâŒ è¯Šæ–­è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
