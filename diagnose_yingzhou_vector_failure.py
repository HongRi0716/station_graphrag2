#!/usr/bin/env python3
"""
è¯Šæ–­è„šæœ¬: æ£€æŸ¥é¢å·å˜æ¥çº¿å›¾.pdfçš„å‘é‡ç´¢å¼•å¤±è´¥åŸå› 
"""

from sqlalchemy import select, and_, desc
from aperag.db.models import Document, DocumentIndex, DocumentIndexType, DocumentIndexStatus, Collection
from aperag.config import get_sync_session
import os
import sys
import json

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def diagnose_yingzhou_vector_failure():
    """è¯Šæ–­é¢å·å˜æ¥çº¿å›¾.pdfçš„å‘é‡ç´¢å¼•å¤±è´¥åŸå› """

    print("=" * 80)
    print("é¢å·å˜æ¥çº¿å›¾.pdf å‘é‡ç´¢å¼•å¤±è´¥è¯Šæ–­å·¥å…·")
    print("=" * 80)

    document_name_pattern = "é¢å·å˜æ¥çº¿å›¾"

    for session in get_sync_session():
        # æŸ¥è¯¢æ–‡æ¡£
        doc_stmt = select(Document).where(
            Document.name.like(f"%{document_name_pattern}%")
        ).order_by(desc(Document.gmt_created))

        doc_result = session.execute(doc_stmt)
        documents = doc_result.scalars().all()

        if not documents:
            print(f"\nâŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£: {document_name_pattern}")
            print("\nğŸ’¡ æç¤º: è¯·ç¡®è®¤æ–‡æ¡£åç§°æ˜¯å¦æ­£ç¡®")
            return

        # å–æœ€æ–°çš„æ–‡æ¡£
        doc = documents[0]
        print(f"\n{'='*80}")
        print(f"æ–‡æ¡£åç§°: {doc.name}")
        print(f"æ–‡æ¡£ID: {doc.id}")
        print(f"æ–‡æ¡£çŠ¶æ€: {doc.status}")
        print(f"æ‰€å±Collection ID: {doc.collection_id}")
        print(f"æ–‡ä»¶å¤§å°: {doc.size:,} bytes ({doc.size / 1024 / 1024:.2f} MB)")
        print(f"åˆ›å»ºæ—¶é—´: {doc.gmt_created}")
        print(f"æ›´æ–°æ—¶é—´: {doc.gmt_updated}")
        print(f"-" * 80)

        # æŸ¥è¯¢Collectionä¿¡æ¯
        collection = session.execute(select(Collection).where(
            Collection.id == doc.collection_id)).scalar_one_or_none()
        
        if collection:
            print(f"\nCollectionä¿¡æ¯:")
            print(f"  Collectionåç§°: {collection.name}")
            print(f"  Collection ID: {collection.id}")
            print(f"  å¯ç”¨å‘é‡ç´¢å¼•: {collection.config.get('enable_vector_index', True) if collection.config else True}")

        # æŸ¥è¯¢æ‰€æœ‰ç´¢å¼•çŠ¶æ€
        index_stmt = select(DocumentIndex).where(
            DocumentIndex.document_id == doc.id
        ).order_by(DocumentIndex.index_type)
        index_result = session.execute(index_stmt)
        indexes = index_result.scalars().all()

        if not indexes:
            print("\nâš ï¸  æœªæ‰¾åˆ°ä»»ä½•ç´¢å¼•è®°å½•")
            print("ğŸ’¡ å¯èƒ½åŸå› : æ–‡æ¡£å°šæœªå¼€å§‹ç´¢å¼•å¤„ç†")
            return

        print(f"\nç´¢å¼•çŠ¶æ€è¯¦æƒ…:")
        vector_index = None
        for idx in indexes:
            status_icon = {
                DocumentIndexStatus.PENDING: "â³",
                DocumentIndexStatus.CREATING: "ğŸ”„",
                DocumentIndexStatus.COMPLETED: "âœ…",
                DocumentIndexStatus.FAILED: "âŒ",
                DocumentIndexStatus.DELETION_IN_PROGRESS: "ğŸ—‘ï¸",
                DocumentIndexStatus.SKIPPED: "â­ï¸"
            }.get(idx.status, "â“")

            print(f"\n  {status_icon} {idx.index_type.value} ç´¢å¼•:")
            print(f"     çŠ¶æ€: {idx.status.value}")
            print(f"     ç‰ˆæœ¬: {idx.version} (å·²å¤„ç†: {idx.observed_version})")
            print(f"     åˆ›å»ºæ—¶é—´: {idx.gmt_created}")
            print(f"     æ›´æ–°æ—¶é—´: {idx.gmt_updated}")

            if idx.index_type == DocumentIndexType.VECTOR:
                vector_index = idx

            if idx.error_message:
                print(f"     âŒ é”™è¯¯ä¿¡æ¯:")
                # æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯ï¼Œæ¯è¡Œç¼©è¿›
                error_lines = idx.error_message.split('\n')
                for line in error_lines:
                    print(f"        {line}")

            if idx.index_data:
                try:
                    data = json.loads(idx.index_data)
                    print(f"     ğŸ“Š ç´¢å¼•æ•°æ®æ‘˜è¦:")
                    if "context_ids" in data:
                        print(f"        - å‘é‡æ•°é‡: {len(data['context_ids'])}")
                    if "chunk_count" in data:
                        print(f"        - å—æ•°é‡: {data['chunk_count']}")
                    if "vector_count" in data:
                        print(f"        - å‘é‡æ•°é‡: {data['vector_count']}")
                    if "vector_size" in data:
                        print(f"        - å‘é‡ç»´åº¦: {data['vector_size']}")
                except:
                    pass

        # é‡ç‚¹åˆ†æå‘é‡ç´¢å¼•å¤±è´¥åŸå› 
        if vector_index and vector_index.status == DocumentIndexStatus.FAILED:
            print(f"\n{'='*80}")
            print("å‘é‡ç´¢å¼•å¤±è´¥åˆ†æ:")
            print("="*80)

            error_msg = vector_index.error_message or ""
            error_lower = error_msg.lower()

            # åˆ†æé”™è¯¯ç±»å‹
            if "embedding" in error_lower or "api key" in error_lower or "rate limit" in error_lower:
                print("\nğŸ” é”™è¯¯ç±»å‹: å‘é‡åµŒå…¥æœåŠ¡é—®é¢˜")
                print("\nå¯èƒ½åŸå› :")
                print("  1. Embedding APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
                print("  2. APIé…é¢ä¸è¶³æˆ–è¾¾åˆ°é€Ÿç‡é™åˆ¶")
                print("  3. ç½‘ç»œæ— æ³•è®¿é—®EmbeddingæœåŠ¡")
                print("  4. EmbeddingæœåŠ¡é…ç½®é”™è¯¯")
                print("\nè§£å†³æ–¹æ¡ˆ:")
                print("  1. æ£€æŸ¥ç¯å¢ƒé…ç½®æ–‡ä»¶ envs/.env æˆ– envs/docker.env.overrides:")
                print("     - EMBEDDING_PROVIDER")
                print("     - EMBEDDING_MODEL")
                print("     - EMBEDDING_SERVICE_URL")
                print("     - EMBEDDING_SERVICE_API_KEY")
                print("  2. éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ")
                print("  3. æ£€æŸ¥APIé…é¢å’Œä½™é¢")
                print("  4. æµ‹è¯•ç½‘ç»œè¿æ¥")

            elif "qdrant" in error_lower or "vector database" in error_lower or "connection" in error_lower:
                print("\nğŸ” é”™è¯¯ç±»å‹: å‘é‡æ•°æ®åº“è¿æ¥é—®é¢˜")
                print("\nå¯èƒ½åŸå› :")
                print("  1. QdrantæœåŠ¡æœªè¿è¡Œ")
                print("  2. Qdrantè¿æ¥é…ç½®é”™è¯¯")
                print("  3. å‘é‡ç»´åº¦ä¸åŒ¹é…")
                print("  4. ç½‘ç»œè¿æ¥é—®é¢˜")
                print("\nè§£å†³æ–¹æ¡ˆ:")
                print("  1. æ£€æŸ¥QdrantæœåŠ¡çŠ¶æ€:")
                print("     docker ps | grep qdrant")
                print("  2. æ£€æŸ¥Qdranté…ç½®:")
                print("     - VECTOR_DB_TYPE=qdrant")
                print("     - VECTOR_DB_CONTEXT")
                print("  3. æµ‹è¯•Qdrantè¿æ¥:")
                print("     curl http://localhost:6333/collections")
                print("  4. é‡å¯QdrantæœåŠ¡:")
                print("     docker-compose restart qdrant")

            elif "parse" in error_lower or "docray" in error_lower or "failed to parse" in error_lower:
                print("\nğŸ” é”™è¯¯ç±»å‹: æ–‡æ¡£è§£æé—®é¢˜")
                print("\nå¯èƒ½åŸå› :")
                print("  1. DocRayæœåŠ¡æœªå¯åŠ¨")
                print("  2. æ–‡æ¡£æ ¼å¼æŸåæˆ–ä¸æ”¯æŒ")
                print("  3. æ–‡æ¡£è¿‡å¤§")
                print("  4. OCRå¤„ç†å¤±è´¥")
                print("\nè§£å†³æ–¹æ¡ˆ:")
                print("  1. æ£€æŸ¥DocRayæœåŠ¡çŠ¶æ€:")
                print("     docker ps | grep docray")
                print("  2. å¦‚æœDocRayæœªè¿è¡Œï¼Œå¯åŠ¨å®ƒ:")
                print("     docker-compose up -d docray")
                print("  3. æŸ¥çœ‹DocRayæ—¥å¿—:")
                print("     docker logs aperag-docray --tail 100")
                print("  4. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å¯ä»¥æ­£å¸¸æ‰“å¼€")

            elif "timeout" in error_lower or "timed out" in error_lower:
                print("\nğŸ” é”™è¯¯ç±»å‹: è¶…æ—¶é—®é¢˜")
                print("\nå¯èƒ½åŸå› :")
                print("  1. æ–‡æ¡£è¿‡å¤§ï¼Œå¤„ç†æ—¶é—´è¿‡é•¿")
                print("  2. APIå“åº”æ…¢")
                print("  3. ç½‘ç»œå»¶è¿Ÿ")
                print("\nè§£å†³æ–¹æ¡ˆ:")
                print("  1. å¢åŠ è¶…æ—¶è®¾ç½®")
                print("  2. æ£€æŸ¥ç½‘ç»œè¿æ¥")
                print("  3. è€ƒè™‘åˆ†æ‰¹å¤„ç†å¤§æ–‡æ¡£")

            elif "content" in error_lower or "empty" in error_lower or "no text" in error_lower:
                print("\nğŸ” é”™è¯¯ç±»å‹: æ–‡æ¡£å†…å®¹ä¸ºç©º")
                print("\nå¯èƒ½åŸå› :")
                print("  1. PDFæ˜¯çº¯å›¾ç‰‡å‹ï¼ˆæ‰«æç‰ˆï¼‰ï¼Œæ²¡æœ‰æ–‡æœ¬å±‚")
                print("  2. OCRæœªæ‰§è¡Œæˆ–å¤±è´¥")
                print("  3. æ–‡æ¡£è§£æåcontentå­—æ®µä¸ºç©º")
                print("\nè§£å†³æ–¹æ¡ˆ:")
                print("  1. æ£€æŸ¥Visionç´¢å¼•æ˜¯å¦æˆåŠŸåˆ›å»ºï¼ˆç”¨äºå›¾ç‰‡åˆ†æï¼‰")
                print("  2. ç¡®ä¿DocRay OCRåŠŸèƒ½æ­£å¸¸å·¥ä½œ")
                print("  3. æ£€æŸ¥æ–‡æ¡£è§£ææ—¥å¿—")

            else:
                print("\nğŸ” é”™è¯¯ç±»å‹: æœªçŸ¥é”™è¯¯")
                print(f"\nå®Œæ•´é”™è¯¯ä¿¡æ¯:")
                print(f"  {error_msg}")

            print(f"\n{'='*80}")
            print("ä¿®å¤æ­¥éª¤:")
            print("="*80)
            print("\n1. æ ¹æ®ä¸Šè¿°åˆ†æä¿®å¤é…ç½®é—®é¢˜")
            print("\n2. é‡å¯ç›¸å…³æœåŠ¡:")
            print("   docker-compose restart celeryworker")
            if "docray" in error_lower:
                print("   docker-compose restart docray")
            if "qdrant" in error_lower:
                print("   docker-compose restart qdrant")
            print("\n3. é‡å»ºå‘é‡ç´¢å¼•:")
            print("   æ–¹æ³•A: é€šè¿‡Webç•Œé¢")
            print("     - è¿›å…¥æ–‡æ¡£è¯¦æƒ…é¡µ")
            print("     - æ‰¾åˆ°VECTORç´¢å¼•")
            print("     - ç‚¹å‡»'é‡å»ºç´¢å¼•'æŒ‰é’®")
            print("\n   æ–¹æ³•B: é€šè¿‡API")
            print(f"     curl -X POST \"http://localhost:8000/api/v1/collections/{doc.collection_id}/documents/{doc.id}/rebuild-indexes\" \\")
            print("       -H \"Content-Type: application/json\" \\")
            print("       -H \"Authorization: Bearer YOUR_TOKEN\" \\")
            print("       -d '{\"index_types\": [\"VECTOR\"]}'")
            print("\n4. æŸ¥çœ‹é‡å»ºæ—¥å¿—:")
            print("   docker logs aperag-celeryworker --tail 200 -f")

        elif vector_index and vector_index.status == DocumentIndexStatus.COMPLETED:
            print(f"\n{'='*80}")
            print("âœ… å‘é‡ç´¢å¼•å·²æˆåŠŸåˆ›å»º")
            print("="*80)
            if vector_index.index_data:
                try:
                    data = json.loads(vector_index.index_data)
                    if "context_ids" in data:
                        print(f"\nå‘é‡æ•°é‡: {len(data['context_ids'])}")
                    if "vector_count" in data:
                        print(f"å‘é‡æ•°é‡: {data['vector_count']}")
                except:
                    pass

        elif not vector_index:
            print(f"\nâš ï¸  æœªæ‰¾åˆ°å‘é‡ç´¢å¼•è®°å½•")
            print("ğŸ’¡ å¯èƒ½åŸå› : å‘é‡ç´¢å¼•å°šæœªåˆ›å»ºæˆ–å·²è¢«åˆ é™¤")

        print(f"\n{'='*80}")
        print("å…¶ä»–æ£€æŸ¥å»ºè®®:")
        print("="*80)
        print("\n1. æŸ¥çœ‹Celery Workeræ—¥å¿—:")
        print("   docker logs aperag-celeryworker --tail 500 | grep -i \"vector\\|embedding\\|{doc.id}\"")
        print("\n2. æ£€æŸ¥ç¯å¢ƒé…ç½®:")
        print("   docker exec aperag-celeryworker env | grep -i \"EMBEDDING\\|VECTOR\"")
        print("\n3. æ£€æŸ¥æœåŠ¡çŠ¶æ€:")
        print("   docker-compose ps")
        print("\n4. æŸ¥çœ‹ç›¸å…³æ–‡æ¡£:")
        print("   - DOCUMENT_INDEX_TROUBLESHOOTING.md")
        print("   - DOCKER_VECTOR_FAILURE_DIAGNOSIS.md")
        print("="*80 + "\n")

        break


if __name__ == "__main__":
    try:
        diagnose_yingzhou_vector_failure()
    except Exception as e:
        print(f"\nâŒ è¯Šæ–­è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

