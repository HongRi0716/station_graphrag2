#!/usr/bin/env python3
"""æ£€æŸ¥é¢å·å˜æ¥çº¿å›¾.pdfçš„Vision-to-Textæ–‡æœ¬å†…å®¹"""

from sqlalchemy import select, and_, desc
from aperag.db.models import Document, Collection
from aperag.utils.utils import generate_vector_db_collection_name
from aperag.config import get_vector_db_connector
from aperag.db.models import DocumentIndex, DocumentIndexType
from aperag.config import get_sync_session
import sys
import os
import json

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def check_vision_text_by_name(document_name_pattern: str):
    """æŒ‰æ–‡æ¡£åç§°æ£€æŸ¥Visionç´¢å¼•çš„å†…å®¹"""

    print("=" * 80)
    print("Vision-to-Textæ–‡æœ¬å†…å®¹æ£€æŸ¥å·¥å…·")
    print("=" * 80)
    print(f"\næŸ¥æ‰¾æ–‡æ¡£: {document_name_pattern}\n")

    for session in get_sync_session():
        # æŸ¥è¯¢æ–‡æ¡£
        doc_stmt = select(Document).where(
            Document.name.like(f"%{document_name_pattern}%")
        ).order_by(desc(Document.gmt_created))

        doc_result = session.execute(doc_stmt)
        documents = doc_result.scalars().all()

        if not documents:
            print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£: {document_name_pattern}")
            return

        # å–æœ€æ–°çš„æ–‡æ¡£
        doc = documents[0]
        print(f"\n{'='*80}")
        print(f"æ–‡æ¡£åç§°: {doc.name}")
        print(f"æ–‡æ¡£ID: {doc.id}")
        print(f"æ–‡æ¡£çŠ¶æ€: {doc.status}")
        print(f"æ‰€å±Collection ID: {doc.collection_id}")
        print(f"åˆ›å»ºæ—¶é—´: {doc.gmt_created}")
        print(f"-" * 80)

        collection = session.execute(select(Collection).where(
            Collection.id == doc.collection_id)).scalar_one_or_none()
        if not collection:
            print("âŒ Collectionä¸å­˜åœ¨")
            return

        # æŸ¥è¯¢Visionç´¢å¼•
        vision_index = session.execute(
            select(DocumentIndex).where(
                and_(
                    DocumentIndex.document_id == doc.id,
                    DocumentIndex.index_type == DocumentIndexType.VISION
                )
            )
        ).scalar_one_or_none()

        if not vision_index:
            print("\nâŒ Visionç´¢å¼•ä¸å­˜åœ¨")
            print("\nğŸ’¡ å¯èƒ½åŸå› :")
            print("   - Visionç´¢å¼•å°šæœªåˆ›å»º")
            print("   - Collectionçš„enable_visionæœªå¯ç”¨")
            return

        print(f"\nğŸ“Š Visionç´¢å¼•çŠ¶æ€: {vision_index.status}")
        print(f"  ç‰ˆæœ¬: {vision_index.version}")
        print(f"  åˆ›å»ºæ—¶é—´: {vision_index.gmt_created}")

        if vision_index.index_data:
            try:
                index_data = json.loads(vision_index.index_data)
                ctx_ids = index_data.get("context_ids", [])
                print(f"\nğŸ“‹ Context IDsæ•°é‡: {len(ctx_ids)}")
                if not ctx_ids:
                    print("âš ï¸  æ²¡æœ‰Context IDsï¼ŒVisionç´¢å¼•å¯èƒ½ä¸ºç©º")
                    return

                # æŸ¥è¯¢å‘é‡å­˜å‚¨ä¸­çš„å†…å®¹
                collection_name = generate_vector_db_collection_name(
                    collection_id=collection.id)
                vector_store = get_vector_db_connector(
                    collection=collection_name)
                qdrant_client = vector_store.connector.client

                print(f"\nä»å‘é‡å­˜å‚¨æ£€ç´¢Vision-to-Textå†…å®¹...")
                print(f"Collectionåç§°: {collection_name}")

                points = qdrant_client.retrieve(
                    collection_name=collection_name,
                    ids=ctx_ids,
                    with_payload=True,
                )

                print(f"âœ… æ£€ç´¢åˆ° {len(points)} ä¸ªç‚¹\n")

                vision_texts = []
                for i, point in enumerate(points, 1):
                    text = None
                    metadata = {}
                    asset_id = None
                    page_idx = None

                    if point.payload:
                        # æ£€æŸ¥_node_content
                        node_content = point.payload.get("_node_content")
                        if node_content and isinstance(node_content, str):
                            try:
                                payload_data = json.loads(node_content)
                                metadata = payload_data.get("metadata", {})
                                if metadata.get("index_method") == "vision_to_text":
                                    text = payload_data.get("text", "")
                                    asset_id = metadata.get("asset_id", "")
                                    page_idx = metadata.get("page_idx")
                            except:
                                pass

                        # æ£€æŸ¥ç›´æ¥payloadç»“æ„
                        if not text or not text.strip():
                            direct_metadata = point.payload.get("metadata", {})
                            if direct_metadata.get("index_method") == "vision_to_text":
                                text = point.payload.get("text", "")
                                if not text and node_content:
                                    try:
                                        payload_data = json.loads(node_content)
                                        text = payload_data.get("text", "")
                                        metadata = payload_data.get(
                                            "metadata", {})
                                    except:
                                        pass
                                asset_id = direct_metadata.get(
                                    "asset_id") or metadata.get("asset_id")
                                page_idx = direct_metadata.get(
                                    "page_idx") if "page_idx" in direct_metadata else metadata.get("page_idx")

                    if text and text.strip():
                        section_info = f"\n{'='*80}\n"
                        section_info += f"Vision-to-Textå†…å®¹ #{i}\n"
                        section_info += f"Point ID: {point.id}\n"
                        if asset_id:
                            section_info += f"Asset ID: {asset_id}\n"
                        if page_idx is not None:
                            section_info += f"Page: {int(page_idx) + 1}\n"
                        section_info += f"{'='*80}\n"
                        section_info += text.strip()
                        section_info += f"\n{'='*80}\n"

                        vision_texts.append(section_info)
                        print(
                            f"âœ… æå–åˆ°Vision-to-Textå†…å®¹ #{i} (é•¿åº¦: {len(text)} å­—ç¬¦)")

                if vision_texts:
                    print(f"\n{'='*80}")
                    print("Vision-to-Textå®Œæ•´å†…å®¹:")
                    print("="*80)
                    print("\n".join(vision_texts))
                    print(f"\n{'='*80}")
                    print(f"æ€»è®¡: {len(vision_texts)} ä¸ªVision-to-Textç‰‡æ®µ")
                    separator = '=' * 80
                    total_chars = sum(
                        len(t.split(separator)[-2]) if separator in t else len(t) for t in vision_texts)
                    print(f"æ€»å­—ç¬¦æ•°: {total_chars}")

                    # åˆ†æå†…å®¹ä¸­æ˜¯å¦åŒ…å«è¿æ¥å…³ç³»æè¿°
                    all_text = "\n".join(vision_texts)
                    connection_keywords = [
                        "è¿æ¥", "é€šè¿‡", "è¿æ¥åˆ°", "è¿æ¥è‡³", "è¿æ¥å…³ç³»", "ç”µæ°”è¿æ¥", "æ¥çº¿", "é€šè¿‡...è¿æ¥"]
                    found_connections = []
                    for keyword in connection_keywords:
                        if keyword in all_text:
                            found_connections.append(keyword)

                    if found_connections:
                        print(f"\nâœ… å‘ç°è¿æ¥å…³ç³»å…³é”®è¯: {', '.join(found_connections)}")
                        print("   è¿™äº›å…³é”®è¯åº”è¯¥èƒ½è¢«çŸ¥è¯†å›¾è°±æå–ä¸ºè¿æ¥å…³ç³»")
                    else:
                        print(f"\nâš ï¸  æœªå‘ç°æ˜æ˜¾çš„è¿æ¥å…³ç³»å…³é”®è¯")
                        print("   è¿™å¯èƒ½æ˜¯çŸ¥è¯†å›¾è°±æ²¡æœ‰è¿æ¥å…³ç³»çš„åŸå› ")
                        print("   å»ºè®®æ£€æŸ¥Vision-to-Textçš„promptæ˜¯å¦åŒ…å«è¿æ¥å…³ç³»æè¿°")
                else:
                    print("\nâš ï¸  æœªæ‰¾åˆ°Vision-to-Textæ–‡æœ¬å†…å®¹")
                    print("\nğŸ’¡ å¯èƒ½åŸå› :")
                    print("   - Visionç´¢å¼•æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
                    print("   - å‘é‡æ•°æ®åº“ä¸­çš„metadataä¸åŒ¹é…")
                    print("   - Visionç´¢å¼•å·²å®Œæˆä½†å†…å®¹ä¸ºç©º")

            except Exception as e:
                print(f"âŒ è§£æç´¢å¼•æ•°æ®å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

        break


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="æ£€æŸ¥æ–‡æ¡£çš„Vision-to-Textæ–‡æœ¬å†…å®¹")
    parser.add_argument(
        "document_name",
        nargs="?",
        default="é¢å·å˜æ¥çº¿å›¾",
        help="æ–‡æ¡£åç§°æˆ–åç§°çš„ä¸€éƒ¨åˆ†(æ”¯æŒæ¨¡ç³ŠåŒ¹é…)"
    )
    args = parser.parse_args()

    try:
        check_vision_text_by_name(args.document_name)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
