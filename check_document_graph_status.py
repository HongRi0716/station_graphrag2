#!/usr/bin/env python3
"""
æ£€æŸ¥æ–‡æ¡£çŸ¥è¯†å›¾è°±å»ºç«‹çŠ¶æ€åŠäº§ç”Ÿæ–‡æœ¬çš„è¯Šæ–­è„šæœ¬
"""

import sys
import os
import json
from datetime import datetime

# Add the project root to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from sqlalchemy import select, and_
    from aperag.db.models import (
        Document,
        DocumentIndex,
        DocumentIndexType,
        DocumentIndexStatus,
        Collection,
    )
    from aperag.config import get_sync_session
    from aperag.schema.utils import parseCollectionConfig
    from aperag.graph import lightrag_manager
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç¯å¢ƒä¸­è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


def check_document_graph_status(document_id: str):
    """æ£€æŸ¥æ–‡æ¡£çš„çŸ¥è¯†å›¾è°±çŠ¶æ€å’Œäº§ç”Ÿçš„æ–‡æœ¬"""

    print("=" * 80)
    print("æ–‡æ¡£çŸ¥è¯†å›¾è°±çŠ¶æ€æ£€æŸ¥å·¥å…·")
    print("=" * 80)
    print(f"\næ–‡æ¡£ID: {document_id}\n")

    # 1. æŸ¥è¯¢æ–‡æ¡£åŸºæœ¬ä¿¡æ¯
    document = None
    collection = None
    graph_index = None

    from aperag.config import get_sync_session

    for session in get_sync_session():
        # æŸ¥è¯¢æ–‡æ¡£
        doc_stmt = select(Document).where(Document.id == document_id)
        doc_result = session.execute(doc_stmt)
        document = doc_result.scalar_one_or_none()

        if not document:
            print(f"âŒ æœªæ‰¾åˆ°æ–‡æ¡£: {document_id}")
            return

        print(f"ğŸ“„ æ–‡æ¡£ä¿¡æ¯:")
        print(f"   åç§°: {document.name}")
        print(f"   çŠ¶æ€: {document.status}")
        print(f"   å¤§å°: {document.size} bytes")
        print(f"   Collection ID: {document.collection_id}")
        print(f"   åˆ›å»ºæ—¶é—´: {document.gmt_created}")
        print(f"   æ›´æ–°æ—¶é—´: {document.gmt_updated}")

        # æŸ¥è¯¢Collection
        collection_stmt = select(Collection).where(
            Collection.id == document.collection_id)
        collection_result = session.execute(collection_stmt)
        collection = collection_result.scalar_one_or_none()

        if collection:
            print(f"\nğŸ“š Collectionä¿¡æ¯:")
            print(f"   ID: {collection.id}")
            print(f"   æ ‡é¢˜: {collection.title}")
            print(f"   çŠ¶æ€: {collection.status}")

            # æ£€æŸ¥çŸ¥è¯†å›¾è°±é…ç½®
            try:
                config = parseCollectionConfig(collection.config)
                enable_kg = getattr(config, 'enable_knowledge_graph', False)
                print(f"   çŸ¥è¯†å›¾è°±å¯ç”¨: {'âœ… å·²å¯ç”¨' if enable_kg else 'âŒ æœªå¯ç”¨'}")
            except Exception as e:
                print(f"   âš ï¸  è§£æé…ç½®å¤±è´¥: {e}")

        # æŸ¥è¯¢GRAPHç´¢å¼•çŠ¶æ€
        graph_index_stmt = select(DocumentIndex).where(
            and_(
                DocumentIndex.document_id == document_id,
                DocumentIndex.index_type == DocumentIndexType.GRAPH
            )
        )
        graph_index_result = session.execute(graph_index_stmt)
        graph_index = graph_index_result.scalar_one_or_none()

        print(f"\n{'='*80}")
        print("ğŸ“Š GRAPHç´¢å¼•çŠ¶æ€")
        print("="*80)

        if not graph_index:
            print("\nâŒ æœªæ‰¾åˆ°GRAPHç´¢å¼•è®°å½•")
            print("   å¯èƒ½åŸå› :")
            print("   - ç´¢å¼•å°šæœªåˆ›å»º")
            print("   - ç´¢å¼•åˆ›å»ºå¤±è´¥ä½†æœªè®°å½•")
            return

        # å®‰å…¨åœ°è·å–çŠ¶æ€å›¾æ ‡
        status_icon_map = {
            DocumentIndexStatus.PENDING: "â³",
            DocumentIndexStatus.CREATING: "ğŸ”„",
            DocumentIndexStatus.ACTIVE: "âœ…",
            DocumentIndexStatus.FAILED: "âŒ",
        }
        # å°è¯•æ·»åŠ SKIPPEDï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            status_icon_map[DocumentIndexStatus.SKIPPED] = "â­ï¸"
        except AttributeError:
            pass

        status_icon = status_icon_map.get(graph_index.status, "â“")

        status_str = graph_index.status.value if hasattr(
            graph_index.status, 'value') else str(graph_index.status)

        print(f"\n{status_icon} çŠ¶æ€: {status_str}")
        print(
            f"   ç‰ˆæœ¬: {graph_index.version} (å·²å¤„ç†: {graph_index.observed_version})")
        print(f"   åˆ›å»ºæ—¶é—´: {graph_index.gmt_created}")
        print(f"   æ›´æ–°æ—¶é—´: {graph_index.gmt_updated}")
        if graph_index.gmt_last_reconciled:
            print(f"   æœ€ååè°ƒæ—¶é—´: {graph_index.gmt_last_reconciled}")

        if graph_index.error_message:
            print(f"\nâŒ é”™è¯¯ä¿¡æ¯:")
            print(f"   {graph_index.error_message}")

        if graph_index.index_data:
            try:
                index_data = json.loads(graph_index.index_data)
                print(f"\nğŸ“Š ç´¢å¼•æ•°æ®æ‘˜è¦:")
                for key, value in index_data.items():
                    if key not in ['context_ids']:  # è·³è¿‡context_idsï¼Œå¤ªé•¿äº†
                        print(f"   - {key}: {value}")
            except Exception as e:
                print(f"\nâš ï¸  æ— æ³•è§£æç´¢å¼•æ•°æ®: {e}")
                print(f"   åŸå§‹æ•°æ®: {str(graph_index.index_data)[:200]}...")

        # å¦‚æœç´¢å¼•æ˜¯ACTIVEçŠ¶æ€ï¼Œæä¾›æŸ¥è¯¢çŸ¥è¯†å›¾è°±çš„å»ºè®®
        if graph_index.status == DocumentIndexStatus.ACTIVE and collection:
            print(f"\n{'='*80}")
            print("ğŸ” çŸ¥è¯†å›¾è°±æ•°æ®æŸ¥è¯¢")
            print("="*80)

            print("\nğŸ’¡ çŸ¥è¯†å›¾è°±å·²æˆåŠŸåˆ›å»ºï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æŸ¥çœ‹:")
            print(
                f"   1. é€šè¿‡APIæŸ¥è¯¢: GET /api/v1/collections/{collection.id}/knowledge-graph")
            print(f"   2. é€šè¿‡Webç•Œé¢æŸ¥çœ‹çŸ¥è¯†å›¾è°±å¯è§†åŒ–")
            print(f"   3. æŸ¥çœ‹ä¸‹é¢çš„æ—¥å¿—ä¿¡æ¯äº†è§£å¤„ç†è¿‡ç¨‹")

        break  # åªå¤„ç†ç¬¬ä¸€ä¸ªsession


def check_celery_logs(document_id: str):
    """æ£€æŸ¥Celeryæ—¥å¿—ä¸­å…³äºè¯¥æ–‡æ¡£çš„ä¿¡æ¯"""
    print(f"\n{'='*80}")
    print("ğŸ“‹ Celeryæ—¥å¿—æ£€æŸ¥ï¼ˆéœ€è¦æ‰‹åŠ¨æ‰§è¡Œï¼‰")
    print("="*80)

    print("\nè¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ç›¸å…³æ—¥å¿—:")
    print(f"\n1. æŸ¥çœ‹æ–‡æ¡£å¤„ç†æ—¥å¿—:")
    print(
        f"   docker logs aperag-celeryworker --tail 500 | grep -i '{document_id}'")

    print(f"\n2. æŸ¥çœ‹çŸ¥è¯†å›¾è°±ç›¸å…³æ—¥å¿—:")
    print(f"   docker logs aperag-celeryworker --tail 500 | grep -i 'graph\\|entity\\|relation'")

    print(f"\n3. æŸ¥çœ‹æœ€è¿‘çš„é”™è¯¯æ—¥å¿—:")
    print(f"   docker logs aperag-celeryworker --tail 200 | grep -i 'error\\|fail\\|exception'")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ£€æŸ¥æ–‡æ¡£çŸ¥è¯†å›¾è°±çŠ¶æ€å’Œäº§ç”Ÿçš„æ–‡æœ¬")
    parser.add_argument(
        "--document-id",
        type=str,
        required=True,
        help="æ–‡æ¡£ID"
    )

    args = parser.parse_args()

    try:
        check_document_graph_status(args.document_id)
        check_celery_logs(args.document_id)

        print(f"\n{'='*80}")
        print("âœ… æ£€æŸ¥å®Œæˆ")
        print("="*80)

    except Exception as e:
        print(f"\nâŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
