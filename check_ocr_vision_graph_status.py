#!/usr/bin/env python3
"""
æ£€æŸ¥dockerä¸­"ä¸»æ¥çº¿.png"é€šè¿‡OCRå’Œvisiontotextæ„å»ºçŸ¥è¯†å›¾è°±çš„è¿è¡ŒçŠ¶æ€
ç»¼åˆæ£€æŸ¥OCRã€Visionç´¢å¼•å’ŒGraphç´¢å¼•çš„çŠ¶æ€
"""

import sys
import os
import json
from datetime import datetime, timezone

# Add the project root to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from sqlalchemy import select, and_, desc
    from aperag.db.models import (
        Document,
        DocumentIndex,
        DocumentIndexType,
        DocumentIndexStatus,
        Collection,
    )
    from aperag.config import get_sync_session
    from aperag.schema.utils import parseCollectionConfig
    from aperag.utils.utils import generate_vector_db_collection_name
    from aperag.config import get_vector_db_connector
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç¯å¢ƒä¸­è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


def find_document_by_name(document_name: str):
    """é€šè¿‡æ–‡ä»¶åæŸ¥æ‰¾æ–‡æ¡£"""
    for session in get_sync_session():
        # å°è¯•ç²¾ç¡®åŒ¹é…
        stmt = select(Document).where(Document.name ==
                                      document_name).order_by(desc(Document.gmt_created))
        result = session.execute(stmt)
        documents = result.scalars().all()

        if not documents:
            # å°è¯•æ¨¡ç³ŠåŒ¹é…
            stmt = select(Document).where(
                Document.name.like(f"%{document_name}%")
            ).order_by(desc(Document.gmt_created))
            result = session.execute(stmt)
            documents = result.scalars().all()

        if len(documents) == 0:
            return None
        elif len(documents) == 1:
            return documents[0]
        else:
            print(f"\nâš ï¸  æ‰¾åˆ° {len(documents)} ä¸ªåŒ¹é…çš„æ–‡æ¡£:")
            for i, doc in enumerate(documents, 1):
                print(
                    f"   {i}. {doc.name} (ID: {doc.id}, çŠ¶æ€: {doc.status}, åˆ›å»ºæ—¶é—´: {doc.gmt_created})")
            print("\nä½¿ç”¨æœ€æ–°çš„æ–‡æ¡£")
            return documents[0]


def check_ocr_status(document_id: str):
    """æ£€æŸ¥OCRå¤„ç†çŠ¶æ€"""
    print(f"\n{'='*80}")
    print("ğŸ” OCRå¤„ç†çŠ¶æ€æ£€æŸ¥")
    print("="*80)

    for session in get_sync_session():
        # æŸ¥è¯¢æ–‡æ¡£çš„è§£æå†…å®¹ï¼ˆé€šè¿‡VECTORç´¢å¼•æŸ¥çœ‹OCRç»“æœï¼‰
        vector_index = session.execute(
            select(DocumentIndex).where(
                and_(
                    DocumentIndex.document_id == document_id,
                    DocumentIndex.index_type == DocumentIndexType.VECTOR
                )
            )
        ).scalar_one_or_none()

        if vector_index and vector_index.index_data:
            try:
                index_data = json.loads(vector_index.index_data)
                chunks_created = index_data.get("chunks_created", 0)
                print(f"\nâœ… å‘é‡ç´¢å¼•å·²åˆ›å»ºï¼ŒåŒ…å« {chunks_created} ä¸ªæ–‡æœ¬å—")

                # å°è¯•ä»å‘é‡å­˜å‚¨ä¸­è·å–OCRæ–‡æœ¬å†…å®¹
                doc = session.execute(
                    select(Document).where(Document.id == document_id)
                ).scalar_one_or_none()

                if doc:
                    collection = session.execute(
                        select(Collection).where(
                            Collection.id == doc.collection_id)
                    ).scalar_one_or_none()

                    if collection and chunks_created > 0:
                        try:
                            collection_name = generate_vector_db_collection_name(
                                collection_id=collection.id
                            )
                            vector_store = get_vector_db_connector(
                                collection=collection_name)
                            qdrant_client = vector_store.connector.client

                            ctx_ids = index_data.get("context_ids", [])
                            if ctx_ids:
                                points = qdrant_client.retrieve(
                                    collection_name=collection_name,
                                    ids=ctx_ids[:3],  # åªå–å‰3ä¸ª
                                    with_payload=True,
                                )

                                ocr_text_found = False
                                for point in points:
                                    if point.payload:
                                        # æ£€æŸ¥_node_contentä¸­çš„æ–‡æœ¬
                                        node_content = point.payload.get(
                                            "_node_content")
                                        if node_content:
                                            try:
                                                payload_data = json.loads(
                                                    node_content)
                                                text = payload_data.get(
                                                    "text", "")
                                                if text:
                                                    ocr_text_found = True
                                                    print(
                                                        f"\nğŸ“ OCRæ–‡æœ¬é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
                                                    print(
                                                        f"   {text[:500]}...")
                                                    print(
                                                        f"\n   æ–‡æœ¬æ€»é•¿åº¦: {len(text)} å­—ç¬¦")
                                                    break
                                            except:
                                                pass

                                        # æ£€æŸ¥ç›´æ¥textå­—æ®µ
                                        text = point.payload.get("text", "")
                                        if text:
                                            ocr_text_found = True
                                            print(f"\nğŸ“ OCRæ–‡æœ¬é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
                                            print(f"   {text[:500]}...")
                                            print(
                                                f"\n   æ–‡æœ¬æ€»é•¿åº¦: {len(text)} å­—ç¬¦")
                                            break

                                if not ocr_text_found:
                                    print("\nâš ï¸  æœªåœ¨å‘é‡å­˜å‚¨ä¸­æ‰¾åˆ°OCRæ–‡æœ¬å†…å®¹")
                                    print("   å¯èƒ½åŸå› :")
                                    print("   - OCRå¤„ç†å¤±è´¥")
                                    print("   - æ–‡æœ¬å†…å®¹ä¸ºç©º")
                        except Exception as e:
                            print(f"\nâš ï¸  æ— æ³•ä»å‘é‡å­˜å‚¨è·å–OCRå†…å®¹: {e}")
            except Exception as e:
                print(f"\nâš ï¸  è§£æå‘é‡ç´¢å¼•æ•°æ®å¤±è´¥: {e}")
        else:
            print("\nâš ï¸  å‘é‡ç´¢å¼•å°šæœªåˆ›å»ºæˆ–æ•°æ®ä¸ºç©º")
            print("   å¯èƒ½åŸå› :")
            print("   - OCRå¤„ç†å°šæœªå®Œæˆ")
            print("   - å‘é‡ç´¢å¼•åˆ›å»ºå¤±è´¥")

        break


def check_vision_index_status(document_id: str):
    """æ£€æŸ¥Visionç´¢å¼•çŠ¶æ€ï¼ˆvisiontotextå¤„ç†ï¼‰"""
    print(f"\n{'='*80}")
    print("ğŸ‘ï¸  Visionç´¢å¼•çŠ¶æ€æ£€æŸ¥ï¼ˆVision-to-Textï¼‰")
    print("="*80)

    for session in get_sync_session():
        vision_index = session.execute(
            select(DocumentIndex).where(
                and_(
                    DocumentIndex.document_id == document_id,
                    DocumentIndex.index_type == DocumentIndexType.VISION
                )
            )
        ).scalar_one_or_none()

        if not vision_index:
            print("\nâŒ æœªæ‰¾åˆ°VISIONç´¢å¼•è®°å½•")
            print("   å¯èƒ½åŸå› :")
            print("   - Visionç´¢å¼•å°šæœªåˆ›å»º")
            print("   - Visionç´¢å¼•åˆ›å»ºå¤±è´¥ä½†æœªè®°å½•")
            return

        status_icon_map = {
            DocumentIndexStatus.PENDING: "â³",
            DocumentIndexStatus.CREATING: "ğŸ”„",
            DocumentIndexStatus.ACTIVE: "âœ…",
            DocumentIndexStatus.FAILED: "âŒ",
        }
        try:
            status_icon_map[DocumentIndexStatus.SKIPPED] = "â­ï¸"
        except AttributeError:
            pass

        status_str = vision_index.status.value if hasattr(
            vision_index.status, 'value') else str(vision_index.status)
        status_icon = status_icon_map.get(vision_index.status, "â“")

        print(f"\n{status_icon} çŠ¶æ€: {status_str}")
        print(
            f"   ç‰ˆæœ¬: {vision_index.version} (å·²å¤„ç†: {vision_index.observed_version})")
        print(f"   åˆ›å»ºæ—¶é—´: {vision_index.gmt_created}")
        print(f"   æ›´æ–°æ—¶é—´: {vision_index.gmt_updated}")

        if vision_index.error_message:
            print(f"\nâŒ é”™è¯¯ä¿¡æ¯:")
            print(f"   {vision_index.error_message}")

        # æ£€æŸ¥Visionç´¢å¼•å†…å®¹
        if vision_index.index_data:
            try:
                index_data = json.loads(vision_index.index_data)
                ctx_ids = index_data.get("context_ids", [])
                print(f"\nğŸ“Š Visionç´¢å¼•æ•°æ®æ‘˜è¦:")
                print(f"   - Context IDsæ•°é‡: {len(ctx_ids)}")

                if ctx_ids and vision_index.status == DocumentIndexStatus.ACTIVE:
                    # å°è¯•è·å–vision-to-textå†…å®¹
                    doc = session.execute(
                        select(Document).where(Document.id == document_id)
                    ).scalar_one_or_none()

                    if doc:
                        collection = session.execute(
                            select(Collection).where(
                                Collection.id == doc.collection_id)
                        ).scalar_one_or_none()

                        if collection:
                            try:
                                collection_name = generate_vector_db_collection_name(
                                    collection_id=collection.id
                                )
                                vector_store = get_vector_db_connector(
                                    collection=collection_name)
                                qdrant_client = vector_store.connector.client

                                points = qdrant_client.retrieve(
                                    collection_name=collection_name,
                                    ids=ctx_ids[:1],  # åªå–ç¬¬ä¸€ä¸ª
                                    with_payload=True,
                                )

                                if points:
                                    point = points[0]
                                    if point.payload:
                                        node_content = point.payload.get(
                                            "_node_content")
                                        if node_content:
                                            try:
                                                payload_data = json.loads(
                                                    node_content)
                                                text = payload_data.get(
                                                    "text", "")
                                                if text:
                                                    print(
                                                        f"\nğŸ“ Vision-to-Textå†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
                                                    print(
                                                        f"   {text[:500]}...")
                                                    print(
                                                        f"\n   å†…å®¹æ€»é•¿åº¦: {len(text)} å­—ç¬¦")
                                            except:
                                                pass
                            except Exception as e:
                                print(f"\nâš ï¸  æ— æ³•ä»å‘é‡å­˜å‚¨è·å–Visionå†…å®¹: {e}")
            except Exception as e:
                print(f"\nâš ï¸  è§£æVisionç´¢å¼•æ•°æ®å¤±è´¥: {e}")

        break


def check_graph_index_status(document_id: str):
    """æ£€æŸ¥Graphç´¢å¼•çŠ¶æ€ï¼ˆçŸ¥è¯†å›¾è°±æ„å»ºï¼‰"""
    print(f"\n{'='*80}")
    print("ğŸ•¸ï¸  çŸ¥è¯†å›¾è°±ç´¢å¼•çŠ¶æ€æ£€æŸ¥")
    print("="*80)

    for session in get_sync_session():
        graph_index = session.execute(
            select(DocumentIndex).where(
                and_(
                    DocumentIndex.document_id == document_id,
                    DocumentIndex.index_type == DocumentIndexType.GRAPH
                )
            )
        ).scalar_one_or_none()

        if not graph_index:
            print("\nâŒ æœªæ‰¾åˆ°GRAPHç´¢å¼•è®°å½•")
            print("   å¯èƒ½åŸå› :")
            print("   - çŸ¥è¯†å›¾è°±ç´¢å¼•å°šæœªåˆ›å»º")
            print("   - çŸ¥è¯†å›¾è°±ç´¢å¼•åˆ›å»ºå¤±è´¥ä½†æœªè®°å½•")
            return

        status_icon_map = {
            DocumentIndexStatus.PENDING: "â³",
            DocumentIndexStatus.CREATING: "ğŸ”„",
            DocumentIndexStatus.ACTIVE: "âœ…",
            DocumentIndexStatus.FAILED: "âŒ",
        }
        try:
            status_icon_map[DocumentIndexStatus.SKIPPED] = "â­ï¸"
        except AttributeError:
            pass

        status_str = graph_index.status.value if hasattr(
            graph_index.status, 'value') else str(graph_index.status)
        status_icon = status_icon_map.get(graph_index.status, "â“")

        print(f"\n{status_icon} çŠ¶æ€: {status_str}")
        print(
            f"   ç‰ˆæœ¬: {graph_index.version} (å·²å¤„ç†: {graph_index.observed_version})")
        print(f"   åˆ›å»ºæ—¶é—´: {graph_index.gmt_created}")
        print(f"   æ›´æ–°æ—¶é—´: {graph_index.gmt_updated}")
        if graph_index.gmt_last_reconciled:
            print(f"   æœ€ååè°ƒæ—¶é—´: {graph_index.gmt_last_reconciled}")

        if graph_index.error_message:
            print(f"\nâŒ é”™è¯¯ä¿¡æ¯:")
            print(f"   {graph_index.error_message}")

        # æ£€æŸ¥Graphç´¢å¼•æ•°æ®
        if graph_index.index_data:
            try:
                index_data = json.loads(graph_index.index_data)
                print(f"\nğŸ“Š çŸ¥è¯†å›¾è°±æ•°æ®æ‘˜è¦:")

                chunks_created = index_data.get("chunks_created", 0)
                entities_extracted = index_data.get("entities_extracted", 0)
                relations_extracted = index_data.get("relations_extracted", 0)

                print(f"   - æ–‡æœ¬å—æ•°é‡: {chunks_created}")
                print(f"   - å®ä½“æ•°é‡: {entities_extracted}")
                print(f"   - å…³ç³»æ•°é‡: {relations_extracted}")

                if graph_index.status == DocumentIndexStatus.ACTIVE:
                    if entities_extracted == 0 and relations_extracted == 0:
                        print(f"\nâš ï¸  è­¦å‘Š: çŸ¥è¯†å›¾è°±å·²åˆ›å»ºï¼Œä½†æœªæå–åˆ°å®ä½“å’Œå…³ç³»")
                        print("   å¯èƒ½åŸå› :")
                        print("   - OCRå’ŒVision-to-Textå†…å®¹ä¸ºç©ºæˆ–è´¨é‡ä¸ä½³")
                        print("   - LLMæ— æ³•ä»å†…å®¹ä¸­æå–å®ä½“å’Œå…³ç³»")
                        print("   - å†…å®¹æ ¼å¼ä¸ç¬¦åˆçŸ¥è¯†å›¾è°±æå–è¦æ±‚")
                    else:
                        print(f"\nâœ… çŸ¥è¯†å›¾è°±æ„å»ºæˆåŠŸ!")
                        print(
                            f"   å·²æå– {entities_extracted} ä¸ªå®ä½“å’Œ {relations_extracted} ä¸ªå…³ç³»")
            except Exception as e:
                print(f"\nâš ï¸  è§£æGraphç´¢å¼•æ•°æ®å¤±è´¥: {e}")

        break


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description="æ£€æŸ¥dockerä¸­å›¾ç‰‡æ–‡ä»¶é€šè¿‡OCRå’Œvisiontotextæ„å»ºçŸ¥è¯†å›¾è°±çš„è¿è¡ŒçŠ¶æ€"
    )
    parser.add_argument(
        "--document-name",
        type=str,
        default="ä¸»æ¥çº¿.png",
        help="æ–‡æ¡£åç§°ï¼ˆé»˜è®¤: ä¸»æ¥çº¿.pngï¼‰"
    )

    args = parser.parse_args()

    print("=" * 80)
    print("OCRå’ŒVision-to-TextçŸ¥è¯†å›¾è°±æ„å»ºçŠ¶æ€æ£€æŸ¥å·¥å…·")
    print("=" * 80)
    print(f"\næŸ¥æ‰¾æ–‡æ¡£: {args.document_name}\n")

    try:
        # 1. æŸ¥æ‰¾æ–‡æ¡£
        document = find_document_by_name(args.document_name)

        if not document:
            print(f"âŒ æœªæ‰¾åˆ°æ–‡æ¡£: {args.document_name}")
            print("\nğŸ’¡ æç¤º: å¦‚æœåœ¨æœ¬åœ°è¿è¡Œå¤±è´¥ï¼Œè¯·åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œ:")
            print(
                f"   docker exec aperag-celeryworker python check_ocr_vision_graph_status.py --document-name '{args.document_name}'")
            sys.exit(1)

        print(f"\n{'='*80}")
        print("ğŸ“„ æ–‡æ¡£ä¿¡æ¯")
        print("="*80)
        print(f"æ–‡æ¡£åç§°: {document.name}")
        print(f"æ–‡æ¡£ID: {document.id}")
        print(f"æ–‡æ¡£çŠ¶æ€: {document.status}")
        print(f"æ–‡ä»¶å¤§å°: {document.size} bytes")
        print(f"åˆ›å»ºæ—¶é—´: {document.gmt_created}")
        print(f"æ›´æ–°æ—¶é—´: {document.gmt_updated}")

        # è®¡ç®—æ›´æ–°æ—¶é—´è·ç¦»ç°åœ¨çš„æ—¶é—´
        if document.gmt_updated:
            now = datetime.now(timezone.utc)
            elapsed = now - document.gmt_updated.replace(
                tzinfo=timezone.utc) if document.gmt_updated.tzinfo is None else now - document.gmt_updated
            print(
                f"è·ç¦»ç°åœ¨: {elapsed.total_seconds():.0f} ç§’ ({elapsed.total_seconds()/60:.1f} åˆ†é’Ÿ)")

        # æŸ¥è¯¢Collectionä¿¡æ¯
        for session in get_sync_session():
            collection = session.execute(
                select(Collection).where(
                    Collection.id == document.collection_id)
            ).scalar_one_or_none()

            if collection:
                print(f"\nğŸ“š Collectionä¿¡æ¯:")
                print(f"   ID: {collection.id}")
                print(f"   æ ‡é¢˜: {collection.title}")
                print(f"   çŠ¶æ€: {collection.status}")

                # æ£€æŸ¥é…ç½®
                try:
                    config = parseCollectionConfig(collection.config)
                    enable_kg = getattr(
                        config, 'enable_knowledge_graph', False)
                    enable_vision = getattr(config, 'enable_vision', False)
                    print(f"   çŸ¥è¯†å›¾è°±å¯ç”¨: {'âœ… å·²å¯ç”¨' if enable_kg else 'âŒ æœªå¯ç”¨'}")
                    print(
                        f"   Visionç´¢å¼•å¯ç”¨: {'âœ… å·²å¯ç”¨' if enable_vision else 'âŒ æœªå¯ç”¨'}")
                except Exception as e:
                    print(f"   âš ï¸  è§£æé…ç½®å¤±è´¥: {e}")
            break

        # 2. æ£€æŸ¥OCRçŠ¶æ€
        check_ocr_status(document.id)

        # 3. æ£€æŸ¥Visionç´¢å¼•çŠ¶æ€
        check_vision_index_status(document.id)

        # 4. æ£€æŸ¥Graphç´¢å¼•çŠ¶æ€
        check_graph_index_status(document.id)

        # 5. ç»¼åˆè¯Šæ–­
        print(f"\n{'='*80}")
        print("ğŸ” ç»¼åˆè¯Šæ–­")
        print("="*80)

        for session in get_sync_session():
            # è·å–æ‰€æœ‰ç´¢å¼•çŠ¶æ€
            indexes = session.execute(
                select(DocumentIndex).where(
                    DocumentIndex.document_id == document.id
                )
            ).scalars().all()

            vision_index = None
            graph_index = None
            vector_index = None

            for idx in indexes:
                if idx.index_type == DocumentIndexType.VISION:
                    vision_index = idx
                elif idx.index_type == DocumentIndexType.GRAPH:
                    graph_index = idx
                elif idx.index_type == DocumentIndexType.VECTOR:
                    vector_index = idx

            print("\nğŸ“‹ å¤„ç†æµç¨‹çŠ¶æ€:")

            # OCRçŠ¶æ€
            if vector_index:
                vector_status = vector_index.status.value if hasattr(
                    vector_index.status, 'value') else str(vector_index.status)
                print(f"   1. OCRå¤„ç† (VECTORç´¢å¼•): {vector_status}")
            else:
                print(f"   1. OCRå¤„ç† (VECTORç´¢å¼•): âŒ æœªåˆ›å»º")

            # Vision-to-TextçŠ¶æ€
            if vision_index:
                vision_status = vision_index.status.value if hasattr(
                    vision_index.status, 'value') else str(vision_index.status)
                print(f"   2. Vision-to-Textå¤„ç† (VISIONç´¢å¼•): {vision_status}")
            else:
                print(f"   2. Vision-to-Textå¤„ç† (VISIONç´¢å¼•): âŒ æœªåˆ›å»º")

            # çŸ¥è¯†å›¾è°±çŠ¶æ€
            if graph_index:
                graph_status = graph_index.status.value if hasattr(
                    graph_index.status, 'value') else str(graph_index.status)
                print(f"   3. çŸ¥è¯†å›¾è°±æ„å»º (GRAPHç´¢å¼•): {graph_status}")
            else:
                print(f"   3. çŸ¥è¯†å›¾è°±æ„å»º (GRAPHç´¢å¼•): âŒ æœªåˆ›å»º")

            # è¯Šæ–­å»ºè®®
            print("\nğŸ’¡ è¯Šæ–­å»ºè®®:")

            if not vector_index or vector_index.status != DocumentIndexStatus.ACTIVE:
                print("   âš ï¸  OCRå¤„ç†æœªå®Œæˆï¼Œè¯·æ£€æŸ¥:")
                print("      - PaddleOCRæœåŠ¡æ˜¯å¦è¿è¡Œ")
                print(
                    "      - æŸ¥çœ‹æ—¥å¿—: docker logs aperag-celeryworker --tail 200 | grep -i 'ocr\\|image'")

            if not vision_index or vision_index.status != DocumentIndexStatus.ACTIVE:
                print("   âš ï¸  Vision-to-Textå¤„ç†æœªå®Œæˆï¼Œè¯·æ£€æŸ¥:")
                print("      - Visionæ¨¡å‹é…ç½®æ˜¯å¦æ­£ç¡®")
                print(
                    "      - æŸ¥çœ‹æ—¥å¿—: docker logs aperag-celeryworker --tail 200 | grep -i 'vision'")

            if not graph_index or graph_index.status != DocumentIndexStatus.ACTIVE:
                print("   âš ï¸  çŸ¥è¯†å›¾è°±æ„å»ºæœªå®Œæˆï¼Œè¯·æ£€æŸ¥:")
                print("      - çŸ¥è¯†å›¾è°±æ˜¯å¦å·²å¯ç”¨")
                print("      - LLMæœåŠ¡é…ç½®æ˜¯å¦æ­£ç¡®")
                print(
                    "      - æŸ¥çœ‹æ—¥å¿—: docker logs aperag-celeryworker --tail 200 | grep -i 'graph\\|entity\\|relation'")

            if (vector_index and vector_index.status == DocumentIndexStatus.ACTIVE) and \
               (vision_index and vision_index.status == DocumentIndexStatus.ACTIVE) and \
               (graph_index and graph_index.status == DocumentIndexStatus.ACTIVE):
                print("   âœ… æ‰€æœ‰å¤„ç†æµç¨‹å·²å®Œæˆ!")

                # æ£€æŸ¥çŸ¥è¯†å›¾è°±æ˜¯å¦æœ‰å®é™…å†…å®¹
                if graph_index.index_data:
                    try:
                        index_data = json.loads(graph_index.index_data)
                        entities = index_data.get("entities_extracted", 0)
                        relations = index_data.get("relations_extracted", 0)
                        if entities == 0 and relations == 0:
                            print("   âš ï¸  ä½†çŸ¥è¯†å›¾è°±ä¸­æœªæå–åˆ°å®ä½“å’Œå…³ç³»ï¼Œå¯èƒ½éœ€è¦:")
                            print("      - æ£€æŸ¥OCRå’ŒVision-to-Textçš„å†…å®¹è´¨é‡")
                            print("      - è°ƒæ•´çŸ¥è¯†å›¾è°±æå–çš„prompt")
                    except:
                        pass

            break

        print(f"\n{'='*80}")
        print("âœ… æ£€æŸ¥å®Œæˆ")
        print("="*80)

    except Exception as e:
        print(f"\nâŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
