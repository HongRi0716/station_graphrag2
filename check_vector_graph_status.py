#!/usr/bin/env python3
"""
æ£€æŸ¥æ–‡æ¡£çš„å‘é‡ç´¢å¼•å’ŒçŸ¥è¯†å›¾è°±ç´¢å¼•çŠ¶æ€
ç”¨äºæ£€æŸ¥dockerä¸­"ä¸»æ¥çº¿.png"çš„å‘é‡å’Œgraphè¿è¡ŒçŠ¶æ€
"""

import sys
import os

# Add the project root to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from sqlalchemy import select, and_, desc
    from aperag.db.models import Document, DocumentIndex, DocumentIndexType, DocumentIndexStatus, Collection
    from aperag.config import get_sync_session
    from aperag.schema.utils import parseCollectionConfig
    import json
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç¯å¢ƒä¸­è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


def check_document_vector_graph_status(document_name_pattern: str):
    """æ£€æŸ¥æ–‡æ¡£çš„å‘é‡ç´¢å¼•å’ŒçŸ¥è¯†å›¾è°±ç´¢å¼•çŠ¶æ€"""

    print("=" * 80)
    print("æ–‡æ¡£å‘é‡ç´¢å¼•å’ŒçŸ¥è¯†å›¾è°±ç´¢å¼•çŠ¶æ€æ£€æŸ¥å·¥å…·")
    print("=" * 80)
    print(f"\næŸ¥æ‰¾æ–‡æ¡£: {document_name_pattern}\n")

    for session in get_sync_session():
        # æŸ¥è¯¢æ–‡æ¡£
        doc_stmt = select(Document).where(
            Document.name.like(f"%{document_name_pattern}%")
        ).order_by(desc(Document.gmt_created))

        doc_result = session.execute(doc_stmt)
        documents = doc_result.scalars().all()

        if not documents:
            print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£: {document_name_pattern}")
            print("\nğŸ’¡ æç¤º: å¦‚æœåœ¨æœ¬åœ°è¿è¡Œå¤±è´¥ï¼Œè¯·åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œ:")
            print(
                f"   docker exec aperag-celeryworker python check_vector_graph_status.py '{document_name_pattern}'")
            return

        for doc in documents:
            print(f"\n{'='*80}")
            print(f"ğŸ“„ æ–‡æ¡£ä¿¡æ¯")
            print(f"{'='*80}")
            print(f"æ–‡æ¡£åç§°: {doc.name}")
            print(f"æ–‡æ¡£ID: {doc.id}")
            print(f"æ–‡æ¡£çŠ¶æ€: {doc.status}")
            print(f"æ‰€å±Collection ID: {doc.collection_id}")
            print(f"æ–‡ä»¶å¤§å°: {doc.size} bytes")
            print(f"åˆ›å»ºæ—¶é—´: {doc.gmt_created}")
            print(f"æ›´æ–°æ—¶é—´: {doc.gmt_updated}")
            print(f"-" * 80)

            # æŸ¥è¯¢Collectioné…ç½®
            collection_stmt = select(Collection).where(
                Collection.id == doc.collection_id)
            collection_result = session.execute(collection_stmt)
            collection = collection_result.scalar_one_or_none()

            if collection:
                print(f"\nğŸ“š Collectionä¿¡æ¯:")
                print(f"  Collectionåç§°: {collection.title}")
                print(f"  CollectionçŠ¶æ€: {collection.status}")

                # æ£€æŸ¥ç´¢å¼•é…ç½®
                try:
                    config = parseCollectionConfig(collection.config)
                    enable_vector = config.enable_vector if hasattr(
                        config, 'enable_vector') else False
                    enable_kg = config.enable_knowledge_graph if hasattr(
                        config, 'enable_knowledge_graph') else False
                    print(f"  å‘é‡ç´¢å¼•å¯ç”¨: {'âœ… å·²å¯ç”¨' if enable_vector else 'âŒ æœªå¯ç”¨'}")
                    print(f"  çŸ¥è¯†å›¾è°±å¯ç”¨: {'âœ… å·²å¯ç”¨' if enable_kg else 'âŒ æœªå¯ç”¨'}")

                    if hasattr(config, 'knowledge_graph_config'):
                        kg_config = config.knowledge_graph_config
                        print(f"  çŸ¥è¯†å›¾è°±é…ç½®:")
                        if hasattr(kg_config, 'language'):
                            print(f"    - è¯­è¨€: {kg_config.language}")
                        if hasattr(kg_config, 'entity_types'):
                            print(f"    - å®ä½“ç±»å‹: {kg_config.entity_types}")
                except Exception as e:
                    print(f"  âš ï¸  è§£æCollectioné…ç½®å¤±è´¥: {e}")
                    print(f"  åŸå§‹é…ç½®: {collection.config}")
            else:
                print(f"\nâš ï¸  æœªæ‰¾åˆ°Collection: {doc.collection_id}")

            # æŸ¥è¯¢æ‰€æœ‰ç´¢å¼•çŠ¶æ€
            index_stmt = select(DocumentIndex).where(
                DocumentIndex.document_id == doc.id
            )
            index_result = session.execute(index_stmt)
            indexes = index_result.scalars().all()

            if not indexes:
                print("\nâš ï¸  æœªæ‰¾åˆ°ä»»ä½•ç´¢å¼•è®°å½•")
                continue

            print("\n" + "=" * 80)
            print("ğŸ“Š ç´¢å¼•çŠ¶æ€è¯¦æƒ…")
            print("=" * 80)

            vector_index = None
            graph_index = None

            for idx in indexes:
                status_icon = {
                    DocumentIndexStatus.PENDING: "â³",
                    DocumentIndexStatus.CREATING: "ğŸ”„",
                    DocumentIndexStatus.ACTIVE: "âœ…",
                    DocumentIndexStatus.FAILED: "âŒ",
                    DocumentIndexStatus.DELETION_IN_PROGRESS: "ğŸ—‘ï¸",
                }.get(idx.status, "â“")
                # å¤„ç†SKIPPEDçŠ¶æ€ï¼ˆå­—ç¬¦ä¸²å€¼ï¼Œä¸åœ¨æšä¸¾ä¸­ï¼‰
                if idx.status.value == "SKIPPED" if hasattr(idx.status, 'value') else str(idx.status) == "SKIPPED":
                    status_icon = "â­ï¸"

                index_type_str = idx.index_type.value if hasattr(idx.index_type, 'value') else str(idx.index_type)
                status_str = idx.status.value if hasattr(idx.status, 'value') else str(idx.status)
                print(f"\n  {status_icon} {index_type_str} ç´¢å¼•:")
                print(f"     çŠ¶æ€: {status_str}")
                print(f"     ç‰ˆæœ¬: {idx.version} (å·²å¤„ç†: {idx.observed_version})")
                print(f"     åˆ›å»ºæ—¶é—´: {idx.gmt_created}")
                print(f"     æ›´æ–°æ—¶é—´: {idx.gmt_updated}")
                if idx.gmt_last_reconciled:
                    print(f"     æœ€ååè°ƒæ—¶é—´: {idx.gmt_last_reconciled}")

                if idx.error_message:
                    print(f"     âŒ é”™è¯¯ä¿¡æ¯:")
                    print(f"        {idx.error_message}")

                # ä¿å­˜å‘é‡å’Œgraphç´¢å¼•å¼•ç”¨
                if idx.index_type == DocumentIndexType.VECTOR:
                    vector_index = idx
                    if idx.index_data:
                        try:
                            data = json.loads(idx.index_data)
                            print(f"     ğŸ“Š å‘é‡ç´¢å¼•æ•°æ®æ‘˜è¦:")
                            if "chunks_created" in data:
                                print(
                                    f"        - å—æ•°é‡: {data['chunks_created']}")
                            if "context_ids" in data:
                                ctx_ids = data.get("context_ids", [])
                                print(f"        - å‘é‡æ•°é‡: {len(ctx_ids)}")
                                if ctx_ids:
                                    print(f"        - å‰5ä¸ªå‘é‡ID: {ctx_ids[:5]}")
                        except:
                            print(
                                f"     ğŸ“Š ç´¢å¼•æ•°æ®: {str(idx.index_data)[:200]}...")

                elif idx.index_type == DocumentIndexType.GRAPH:
                    graph_index = idx
                    if idx.index_data:
                        try:
                            data = json.loads(idx.index_data)
                            print(f"     ğŸ“Š çŸ¥è¯†å›¾è°±æ•°æ®æ‘˜è¦:")
                            if "chunks_created" in data:
                                print(
                                    f"        - å—æ•°é‡: {data['chunks_created']}")
                            if "entities_extracted" in data:
                                print(
                                    f"        - å®ä½“æ•°é‡: {data['entities_extracted']}")
                            if "relations_extracted" in data:
                                print(
                                    f"        - å…³ç³»æ•°é‡: {data['relations_extracted']}")
                            if "status" in data:
                                print(f"        - å¤„ç†çŠ¶æ€: {data['status']}")
                        except:
                            print(
                                f"     ğŸ“Š ç´¢å¼•æ•°æ®: {str(idx.index_data)[:200]}...")

            # è¯Šæ–­ç»“æœ
            print(f"\n{'='*80}")
            print("ğŸ” è¯Šæ–­ç»“æœ")
            print("=" * 80)

            # å‘é‡ç´¢å¼•è¯Šæ–­
            print("\nğŸ“Œ å‘é‡ç´¢å¼•çŠ¶æ€:")
            if not collection:
                print("   âŒ Collectionä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºå‘é‡ç´¢å¼•")
            elif not enable_vector:
                print("   âŒ å‘é‡ç´¢å¼•æœªå¯ç”¨")
            elif not vector_index:
                print("   âŒ æœªæ‰¾åˆ°VECTORç´¢å¼•è®°å½•")
                print("   ğŸ’¡ å¯èƒ½åŸå› :")
                print("      - ç´¢å¼•åˆ›å»ºä»»åŠ¡å°šæœªæ‰§è¡Œ")
                print("      - ç´¢å¼•åˆ›å»ºå¤±è´¥ä½†æœªè®°å½•é”™è¯¯")
            else:
                if vector_index.status == DocumentIndexStatus.FAILED:
                    print(f"   âŒ å‘é‡ç´¢å¼•åˆ›å»ºå¤±è´¥")
                    print(f"      é”™è¯¯: {vector_index.error_message}")
                elif vector_index.status == DocumentIndexStatus.PENDING:
                    print(f"   â³ å‘é‡ç´¢å¼•ç­‰å¾…å¤„ç†ä¸­")
                    print(
                        f"      version={vector_index.version}, observed={vector_index.observed_version}")
                elif vector_index.status == DocumentIndexStatus.CREATING:
                    print(f"   ğŸ”„ å‘é‡ç´¢å¼•æ­£åœ¨åˆ›å»ºä¸­")
                elif vector_index.status == DocumentIndexStatus.ACTIVE:
                    print(f"   âœ… å‘é‡ç´¢å¼•å·²æˆåŠŸåˆ›å»º")
                elif (hasattr(vector_index.status, 'value') and vector_index.status.value == "SKIPPED") or str(vector_index.status) == "SKIPPED":
                    print(f"   â­ï¸  å‘é‡ç´¢å¼•è¢«è·³è¿‡")
                    print(f"      åŸå› : {vector_index.error_message or 'æœªçŸ¥'}")

            # çŸ¥è¯†å›¾è°±ç´¢å¼•è¯Šæ–­
            print("\nğŸ“Œ çŸ¥è¯†å›¾è°±ç´¢å¼•çŠ¶æ€:")
            if not collection:
                print("   âŒ Collectionä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºçŸ¥è¯†å›¾è°±")
            elif not enable_kg:
                print("   âŒ çŸ¥è¯†å›¾è°±æœªå¯ç”¨")
            elif not graph_index:
                print("   âŒ æœªæ‰¾åˆ°GRAPHç´¢å¼•è®°å½•")
                print("   ğŸ’¡ å¯èƒ½åŸå› :")
                print("      - ç´¢å¼•åˆ›å»ºä»»åŠ¡å°šæœªæ‰§è¡Œ")
                print("      - ç´¢å¼•åˆ›å»ºå¤±è´¥ä½†æœªè®°å½•é”™è¯¯")
            else:
                if graph_index.status == DocumentIndexStatus.FAILED:
                    print(f"   âŒ çŸ¥è¯†å›¾è°±ç´¢å¼•åˆ›å»ºå¤±è´¥")
                    print(f"      é”™è¯¯: {graph_index.error_message}")
                elif graph_index.status == DocumentIndexStatus.PENDING:
                    print(f"   â³ çŸ¥è¯†å›¾è°±ç´¢å¼•ç­‰å¾…å¤„ç†ä¸­")
                    print(
                        f"      version={graph_index.version}, observed={graph_index.observed_version}")
                elif graph_index.status == DocumentIndexStatus.CREATING:
                    print(f"   ğŸ”„ çŸ¥è¯†å›¾è°±ç´¢å¼•æ­£åœ¨åˆ›å»ºä¸­")
                elif graph_index.status == DocumentIndexStatus.ACTIVE:
                    print(f"   âœ… çŸ¥è¯†å›¾è°±ç´¢å¼•å·²æˆåŠŸåˆ›å»º")
                elif (hasattr(graph_index.status, 'value') and graph_index.status.value == "SKIPPED") or str(graph_index.status) == "SKIPPED":
                    print(f"   â­ï¸  çŸ¥è¯†å›¾è°±ç´¢å¼•è¢«è·³è¿‡")
                    print(f"      åŸå› : {graph_index.error_message or 'æœªçŸ¥'}")

            # è§£å†³æ–¹æ¡ˆå»ºè®®
            print(f"\n{'='*80}")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®")
            print("=" * 80)

            if vector_index and vector_index.status == DocumentIndexStatus.PENDING:
                print("\nğŸ“Œ å‘é‡ç´¢å¼•å¤„äºPENDINGçŠ¶æ€:")
                print("   1. æ£€æŸ¥Celery Workeræ˜¯å¦è¿è¡Œ:")
                print("      docker ps | grep celeryworker")
                print("   2. æ£€æŸ¥Celery Beatæ˜¯å¦è¿è¡Œ:")
                print("      docker ps | grep celerybeat")
                print("   3. æ‰‹åŠ¨è§¦å‘reconciliation:")
                print("      docker exec aperag-celeryworker python -c \\")
                print(
                    "        'from config.celery_tasks import reconcile_indexes_task; reconcile_indexes_task()'")
                print("   4. æŸ¥çœ‹Celeryæ—¥å¿—:")
                print(
                    "      docker logs aperag-celeryworker --tail 200 | grep -i 'vector\\|reconcile'")

            if graph_index and graph_index.status == DocumentIndexStatus.PENDING:
                print("\nğŸ“Œ çŸ¥è¯†å›¾è°±ç´¢å¼•å¤„äºPENDINGçŠ¶æ€:")
                print("   1. æ£€æŸ¥Celery Workeræ˜¯å¦è¿è¡Œ")
                print("   2. æ£€æŸ¥LLMæœåŠ¡é…ç½®ï¼ˆç”¨äºå®ä½“å’Œå…³ç³»æå–ï¼‰")
                print("   3. æ£€æŸ¥å›¾æ•°æ®åº“è¿æ¥ï¼ˆå¦‚æœä½¿ç”¨Neo4j/NebulaGraphï¼‰")
                print("   4. æ‰‹åŠ¨è§¦å‘reconciliationï¼ˆåŒä¸Šï¼‰")
                print("   5. æŸ¥çœ‹Celeryæ—¥å¿—:")
                print(
                    "      docker logs aperag-celeryworker --tail 200 | grep -i 'graph\\|reconcile'")

            if vector_index and vector_index.status == DocumentIndexStatus.FAILED:
                print("\nğŸ“Œ å‘é‡ç´¢å¼•åˆ›å»ºå¤±è´¥:")
                print("   1. æ£€æŸ¥å‘é‡æ•°æ®åº“è¿æ¥")
                print("   2. æ£€æŸ¥embeddingæœåŠ¡é…ç½®")
                print("   3. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼ˆè§ä¸Šæ–¹ï¼‰")
                print("   4. é€šè¿‡APIæˆ–Webç•Œé¢é‡å»ºå‘é‡ç´¢å¼•")

            if graph_index and graph_index.status == DocumentIndexStatus.FAILED:
                print("\nğŸ“Œ çŸ¥è¯†å›¾è°±ç´¢å¼•åˆ›å»ºå¤±è´¥:")
                print("   1. æ£€æŸ¥LLMæœåŠ¡é…ç½®ï¼ˆç”¨äºå®ä½“å’Œå…³ç³»æå–ï¼‰")
                print("   2. æ£€æŸ¥å›¾æ•°æ®åº“è¿æ¥")
                print("   3. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼ˆè§ä¸Šæ–¹ï¼‰")
                print("   4. é€šè¿‡APIæˆ–Webç•Œé¢é‡å»ºGRAPHç´¢å¼•")

            if (vector_index and vector_index.status == DocumentIndexStatus.ACTIVE) and \
               (graph_index and graph_index.status == DocumentIndexStatus.ACTIVE):
                print("\nâœ… å‘é‡ç´¢å¼•å’ŒçŸ¥è¯†å›¾è°±ç´¢å¼•éƒ½å·²æˆåŠŸåˆ›å»ºï¼")

            print(f"\n{'='*80}\n")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="æ£€æŸ¥æ–‡æ¡£çš„å‘é‡ç´¢å¼•å’ŒçŸ¥è¯†å›¾è°±ç´¢å¼•çŠ¶æ€")
    parser.add_argument(
        "document_name",
        nargs="?",
        default="ä¸»æ¥çº¿.png",
        help="æ–‡æ¡£åç§°æˆ–åç§°çš„ä¸€éƒ¨åˆ†(æ”¯æŒæ¨¡ç³ŠåŒ¹é…)"
    )

    args = parser.parse_args()

    try:
        check_document_vector_graph_status(args.document_name)
    except Exception as e:
        print(f"\nâŒ è¯Šæ–­è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
